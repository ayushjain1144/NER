{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_NN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcNP9WfcFuC1V66UbO1jDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushjain1144/NER/blob/master/NER_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eRcJnO4Xyl",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGT8kFRu4VyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYDqojOAmafp",
        "colab_type": "text"
      },
      "source": [
        "# Loading the features and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRlPGzpimTlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "4a1510fb-a34b-4b64-ab6a-cef672038cb6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ln -s content/gdrive/My\\ Drive/NER /ner_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOChUptq2VdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "99fb4bcf-d9e9-4940-b0b5-9b3035e877e8"
      },
      "source": [
        "%cd ..\n",
        "%cd /ner_dir\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/content/gdrive/My Drive/NER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvCu2tfk2nVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "39373b20-9f08-4f8b-d5db-b5967086045b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "activations.py\t\t  loss.py\t\tREADME.md\n",
            "Conll.ipynb\t\t  NER_NN.ipynb\t\ttest_features.npy\n",
            "dataset\t\t\t  NER_NN_network.ipynb\ttrain_features.npy\n",
            "initial_experiment.ipynb  nn.py\t\t\tval_features.npy\n",
            "initialization.py\t  __pycache__\t\tvocab.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbtd6U_5-wDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import activations\n",
        "import loss\n",
        "import initialization as init_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkgIekd-4RmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = np.load('vocab.npy')\n",
        "train_features = np.load('train_features.npy')\n",
        "test_features = np.load('test_features.npy')\n",
        "val_features = np.load('val_features.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N02tcTD9H5cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "34787ec0-ebba-4dc0-f5c5-e54112a50406"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(vocab.shape)\n",
        "print(test_features.shape)\n",
        "print(val_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(204566, 900)\n",
            "(26872, 300)\n",
            "(46665, 900)\n",
            "(51577, 900)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftzW0XaYlGxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "a889c64e-f1da-408c-d791-e4ad9ac5f64c"
      },
      "source": [
        "train_features[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.        ,  0.        , ...,  0.03063965,\n",
              "        -0.10351562,  0.203125  ],\n",
              "       [-0.92605459, -1.13792351, -0.7880129 , ..., -0.70885908,\n",
              "        -1.25367734,  0.080868  ],\n",
              "       [ 0.00982666,  0.2265625 ,  0.28125   , ..., -0.02233887,\n",
              "         0.12695312, -0.04150391],\n",
              "       ...,\n",
              "       [-1.97499414,  0.00412577,  0.30153385, ...,  0.25416797,\n",
              "        -0.06190594, -0.14426987],\n",
              "       [-0.08007812,  0.15625   , -0.35351562, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 1.        ,  0.        ,  0.        , ...,  0.65237435,\n",
              "        -0.67437781,  0.23527849]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEzSQKPHJv7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = 1\n",
        "word_vector_dim = 300\n",
        "num_tags = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K1vS8CzG0W0",
        "colab_type": "text"
      },
      "source": [
        "# Neural Netwwork Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fStbOrS4yW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_architecture = [\n",
        "  {\"layer_size\": 900, \"activation\": \"none\"},\n",
        "  {\"layer_size\": 300, \"activation\": \"relu\"},\n",
        "  {\"layer_size\": 100, \"activation\": \"relu\"},\n",
        "  {\"layer_size\":10, \"activation\": \"softmax\"}\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHYrA8lQmW-f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4966dbfe-8207-4427-b818-4107b9494469"
      },
      "source": [
        "nn_architecture[1]['activation']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'relu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apFzoggrMYW_",
        "colab_type": "text"
      },
      "source": [
        "# Initialize Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31FNVIQaL_5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(nn_architecture, initialization = \"range_initialization\", seed=5):\n",
        "\n",
        "  parameters = {}\n",
        "  num_layers = len(nn_architecture)\n",
        "\n",
        "  for i in range(1, num_layers):\n",
        "\n",
        "    if initialization == \"range_initialization\":\n",
        "      parameters['W' + str(i)] = init_layer.range_initializtion(nn_architecture[i][\"layer_size\"],\n",
        "                                            nn_architecture[i - 1][\"layer_size\"], seed)\n",
        "    else:\n",
        "      parameters['W' + str(i)] = init_layer.random_initializtion(nn_architecture[i][\"layer_size\"],\n",
        "                                            nn_architecture[i - 1][\"layer_size\"], seed)\n",
        "\n",
        "    parameters['b' + str(i)] = np.zeros((nn_architecture[i][\"layer_size\"], 1))\n",
        "\n",
        "  return parameters"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk0yEPOsggOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initialize_parameters(nn_architecture, initialization=\"range_initialization\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RojXQmNkcTjY",
        "colab_type": "text"
      },
      "source": [
        "# Forward Propogation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg5s5MaUQKYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Z = W * X + b\n",
        "# Here A is output of previous layer\n",
        "\n",
        "def linear_forward(A_prev, W, b):\n",
        "  return np.dot(W, A_prev) + b\n",
        "\n",
        "# apply activation h:  A = h(X) \n",
        "def apply_activation(A, activation, alpha=0.01):\n",
        "\n",
        "  if activation == \"sigmoid\":\n",
        "    return activations.sigmoid(A)\n",
        "  elif activation == \"tanh\":\n",
        "    return activations.tanh(A)\n",
        "  elif activation == \"relu\":\n",
        "    return activations.relu(A)\n",
        "  elif activation == \"leaky_relu\":\n",
        "    return activations.leaky_relu(A, alpha)\n",
        "  elif activation == 'none':\n",
        "    return A;\n",
        "  else:\n",
        "    print(f\"ERROR: {activation} activation not supported\")\n",
        "    sys.exit(1)\n",
        "  \n",
        "# driver forward propogation\n",
        "def model_forward(X, parameters, nn_architecture, alpha=0.01):\n",
        "\n",
        "  forward_cache = {}\n",
        "  A = X\n",
        "  num_layers = len(nn_architecture)\n",
        "\n",
        "  for i in range(1, num_layers):\n",
        "    A_prev = A\n",
        "    W = parameters[\"W\" + str(i)]\n",
        "    b = parametes[\"b\" + str(i)]\n",
        "\n",
        "    Z = linear_forward(A_prev, W, b)\n",
        "    activation = nn[i]['activation']\n",
        "    A = apply_activation(Z, activation, alpha)\n",
        "\n",
        "    forward_cache['Z' + str(i)] = Z\n",
        "    forward_cache['A' + str(i - 1)] = A\n",
        "\n",
        "  return A, forward_cache  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiILZ1FMuJA",
        "colab_type": "text"
      },
      "source": [
        "# Backpropogation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaNyla5vMtrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_backward(dz, cache):\n",
        "  A_prev, W, b = cache\n",
        "  m = A_prev.shape[1]\n",
        "\n",
        "  dw = (1 / m) * np.dot(dz, A_prev.T)\n",
        "  db = (1 / m) * np.sum(dZ, axis=1, keepims=True)\n",
        "  dA_prev = np.dot(W.T, dZ)\n",
        "\n",
        "  assert dA_prev.shape == A_prev.shape\n",
        "  assert dW.shape == W.shape\n",
        "  assert db.shape == b.shape\n",
        "\n",
        "  return dA_prev, dw, db      "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSHajBeXr9fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_activation_backward(dA, cache, activation_fn):\n",
        "  linear_cache, activation_cache = cache\n",
        "\n",
        "  if activation_fn == \"sigmoid\":\n",
        "    dZ = activations.sigmoid_backward(dA, activation_cache)\n",
        "    dA_prev, dw, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "  elif activation_fn == \"tanh\":\n",
        "    dZ = activations.sigmoid_backward(dA, activation_cache)\n",
        "    dA_prev, dw, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "  elif activation_fn == \"relu\":\n",
        "    dZ = activations.sigmoid_backward(dA, activation_cache)\n",
        "    dA_prev, dw, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "  elif activation_fn == \"leaky_relu\":\n",
        "    dZ = activations.sigmoid_backward(dA, activation_cache)\n",
        "    dA_prev, dw, db = linear_backward(dZ, linear_cache)\n",
        "  \n",
        "  elif activation_fn == \"none\":\n",
        "    dZ = dA\n",
        "    dA_prev, dw, db = linear_backward(dZ, linear_cache)\n",
        "  \n",
        "  else:\n",
        "    print(\"Activation not available\")\n",
        "    sys.exit(1)\n",
        "\n",
        "  return dA_prev, dw, db\n",
        "\n",
        "  \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKQVgsCqetdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_backward(AL, y, caches, nn_architecture):\n",
        "   \n",
        "  y = y.reshape(AL.shape)\n",
        "  L = len(caches)\n",
        "  grads = {}\n",
        "\n",
        "  dAL = np.divide(AL - y, np.multiply(AL, 1 - AL))\n",
        "\n",
        "  grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = \\\n",
        "             apply_activation_backward(dAL, caches[L-1], nn_architecture[L-1]['activation'])\n",
        "\n",
        "  for l in range(L - 1, 0, -1):\n",
        "    current_cache = caches[l - 1]\n",
        "    grads[\"dA\" + str(l - 1)], grads[\"dW\" + str(l)],  \\\n",
        "        grads[\"db\" + str(l)] = apply_activation_backward(\n",
        "            grads[\"dA\" + str(l)], current_cache, \n",
        "            nn_architecture[l]['activation']\n",
        "        )\n",
        "  return grads"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIGxsD-84Nhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters, grads, lr):\n",
        "\n",
        "  L = len(parameters)\n",
        "\n",
        "  for l in range(1, L + 1):\n",
        "    parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - \\\n",
        "            lr * grads[\"dW\" + str(l)]\n",
        "    parametets[\"b\" + str(l)] = parameters[\"b\" + str(l)] - \\\n",
        "            lr * grads[\"db\" + str(l)]\n",
        "  return parameters"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sl_Wp-H5otj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}