{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conll.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgskAbjwy/JUmL99fisMrM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCIhRSJdTa4n",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcnW6tZ9NcxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, tnrange\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NmeeldkNqYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from gensim import models\n",
        "import copy\n",
        "import os\n",
        "from io import StringIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5gGwn4eTemk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Keras module is only used for PREPROCESSING not TRAINING ######\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-x1ZDqNcNyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global variables\n",
        "\n",
        "# n gram model  = 2 * C + 1\n",
        "C = 1\n",
        "word_vector_dim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv4nKMQnTClV",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNka7S4aS5n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko7FngSbUzpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_base_dir = './dataset/'\n",
        "train_data_file = os.path.join(dataset_base_dir, 'train.txt')\n",
        "val_data_file = os.path.join(dataset_base_dir, 'valid.txt')\n",
        "test_data_file = os.path.join(dataset_base_dir, 'test.txt')\n",
        "\n",
        "train_data = open(train_data_file, 'r').read().lower()\n",
        "test_data = open(test_data_file, 'r').read().lower()\n",
        "val_data = open(val_data_file, 'r').read().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFbfG5WViBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -20 dataset/train.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO8HVgOXV4Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -20 dataset/test.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBCrANWACB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -20 dataset/valid.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekSGn1gKWIoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUVhTDgnWehq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINDATA = StringIO(train_data)\n",
        "\n",
        "train_df = pd.read_csv(TRAINDATA, sep=\" \", header=None)\n",
        "train_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
        "train_df = train_df[1:]\n",
        "\n",
        "TESTDATA = StringIO(test_data)\n",
        "test_df = pd.read_csv(TESTDATA, sep=\" \", header=None)\n",
        "test_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
        "test_df = test_df[1:]\n",
        "\n",
        "VALDATA = StringIO(val_data)\n",
        "val_df = pd.read_csv(VALDATA, sep=\" \", header=None)\n",
        "val_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
        "val_df = val_df[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9RUEJLld9U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[250:300]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI34wYUQiJr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kpe0Nk5O-VA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUrLZyDuc_Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This means that our model needs to predict NULL as named entity recognition\n",
        "\n",
        "val_df[val_df.isnull().any(axis=1)][\"pos_tag\"].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S59BcROOAiIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[train_df.isnull().any(axis=1)][\"pos_tag\"].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj0KHCiXBGgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iJJstD3ggSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
        "test_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
        "val_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
        "# train_df[train_df['NER_tag'] == 'no_tag']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4boZP1SgwoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.dropna()\n",
        "test_df.dropna()\n",
        "val_df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHEifUShLJNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpl50_V-Uzmp",
        "colab_type": "text"
      },
      "source": [
        "# Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm-eSZQuPBpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = train_df.shape[0]\n",
        "num_val = val_df.shape[0]\n",
        "num_test = test_df.shape[0]\n",
        "\n",
        "train_word_set = set(train_df[\"word\"].to_list())\n",
        "test_word_set = set(test_df[\"word\"].to_list())\n",
        "val_word_set = set(val_df[\"word\"].to_list())\n",
        "\n",
        "word_set = train_word_set.union(test_word_set, val_word_set)\n",
        "word_list = list(word_set)\n",
        "word_list.extend(['start_tk', 'end_tk'])\n",
        "print(f\"Total unique words: {len(word_list)}\")\n",
        "\n",
        "ner_tags_list = list(set(train_df['NER_tag'].to_list()))\n",
        "print(f\"Unique Ner Tags: {ner_tags_list}, number: {len(ner_tags_list)}\")\n",
        "\n",
        "num_words = len(word_list)\n",
        "num_tags = len(ner_tags_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBrzuz-LQQL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convering the string data to indices dictionary\n",
        "\n",
        "word2idx = {w: i for i, w in enumerate(word_list)}\n",
        "tag2idx = {t: i for i, t in enumerate(ner_tags_list)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5T6lnnyVBOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEjJ0Q9kgCSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7tLFretLcYA",
        "colab_type": "text"
      },
      "source": [
        "# Forming train and test sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zK2ZiNlig9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tagged_sentences(df):\n",
        "  tagged_list = [(w, t) for w, t in zip(df[\"word\"], df[\"NER_tag\"])]\n",
        "  final = []\n",
        "\n",
        "  for ele in tagged_list:\n",
        "\n",
        "    if not final:  # if list is empty\n",
        "      final.append([ele])\n",
        "    \n",
        "    elif final[-1][-1][0] == '.': # if the last tuple of last list is ('.', ..), form new list\n",
        "      final.append([ele])\n",
        "\n",
        "    else:       # add it to running list\n",
        "      final[-1].append(ele) \n",
        "\n",
        "  return final\n",
        "   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTrmpcAbQhoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences = get_tagged_sentences(train_df)\n",
        "test_sentences = get_tagged_sentences(test_df)\n",
        "val_sentences = get_tagged_sentences(val_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El3FPswDQjm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_sentences[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA2mvqjLSYAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_train = len(max(train_sentences, key=len))\n",
        "max_len_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvKmmmY1merl",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FggdzoYQijPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "# converting into indices\n",
        "X_train = [[word2idx[w[0]] for w in s] for s in train_sentences]\n",
        "X_val = [[word2idx[w[0]] for w in s] for s in val_sentences]\n",
        "X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n",
        "\n",
        "# padding with Max len = 512\n",
        "X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value=MAX_LEN + 1)\n",
        "X_val = pad_sequences(maxlen=MAX_LEN, sequences=X_val, padding=\"post\", value=MAX_LEN + 1)\n",
        "X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value=MAX_LEN + 1)\n",
        "\n",
        "# converting tags to indices\n",
        "y_train = [[tag2idx[w[1]] for w in s] for s in train_sentences]\n",
        "y_val = [[tag2idx[w[1]] for w in s] for s in val_sentences]\n",
        "y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]\n",
        "\n",
        "# padding with Max len = 512\n",
        "y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
        "y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
        "y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
        "\n",
        "\n",
        "# Making labels to one hot encoded\n",
        "\n",
        "y_train = [to_categorical(i, num_classes=num_tags) for i in y_train]\n",
        "y_val = [to_categorical(i, num_classes=num_tags) for i in y_val]\n",
        "y_test = [to_categorical(i, num_classes=num_tags) for i in y_test]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BZoxsoVlB5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCxUSUY8mimK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgXQ9s5iifhH",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59XokNFVEpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google's pretrained word2vec model\n",
        "\n",
        "word2vec_model = models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=10 ** 5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFjza2m7nCn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = word2vec_model[\"computer\"]\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ultLjMESHg6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.random.rand(*a.shape).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHs__xXUBLSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word2vec_indices(vocabulary):\n",
        "  \"\"\"returns wordvec index list and the number of oov words\"\"\"\n",
        "\n",
        "  vocab_matrix  = np.zeros(shape=(len(word_list), word_vector_dim))\n",
        "  oov = 0\n",
        "\n",
        "  for s, idx in vocabulary.items():\n",
        "\n",
        "    try:\n",
        "      vocab_matrix[idx] = word2vec_model[s]\n",
        "\n",
        "    except:\n",
        "      if s == 'start_tk':\n",
        "        n = np.zeros_like(a)\n",
        "        n[0] = 1\n",
        "        vocab_matrix[idx] = n\n",
        "      elif s == 'end_tk':\n",
        "        n = np.zeros_like(a)\n",
        "        n[1] = 1\n",
        "        vocab_matrix[idx] = n\n",
        "      else:\n",
        "        oov += 1\n",
        "        vocab_matrix[idx] = np.random.randn(*a.shape)\n",
        "  return vocab_matrix, oov"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEDtsYIQEwJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_matrix, oov = get_word2vec_indices(word2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncDN8YKfFJd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpsOS1FSC8je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = np.zeros_like(a)\n",
        "n[0] = 1\n",
        "n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDEQlg9JZedt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# window size = 2 * c + 1; \n",
        "def append_start_end_marker(sentences, C=1):\n",
        "  start_set = [('start_tk', 'no_tag') for i in range(C)]\n",
        "  end_set = [('end_tk', 'no_tag') for i in range(C)]\n",
        "\n",
        "  mod_sentences = []\n",
        "  n_gram = []\n",
        "  labels = []\n",
        "  for sent in sentences:\n",
        "    mod_sentences = [ *start_set,  *sent,  *end_set]\n",
        "\n",
        "    for i in range(len(mod_sentences) - (2 * C)):\n",
        "      n_gram.append([word[0] for word in mod_sentences[i: i+ 2 * C + 1]])\n",
        "      labels.append(mod_sentences[i + C ][1])\n",
        "      \n",
        "\n",
        "  return n_gram, labels\n",
        "\n",
        "train_n_grams, train_labels = append_start_end_marker(train_sentences, C)\n",
        "test_n_grams, test_labels = append_start_end_marker(test_sentences, C)\n",
        "val_n_grams, val_labels = append_start_end_marker(val_sentences, C)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxWXloUlblnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_n_grams[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74jclUGK9Vg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRyHH1yv9fGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etHDEtyqI7lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_matrix[word2idx['start_tk']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF38_HJ8Ir_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_wordvec_features(n_grams):\n",
        "\n",
        "  features = np.zeros(shape=(len(n_grams), (2 * C + 1) * word_vector_dim))\n",
        "\n",
        "  for i in range(len(n_grams)):\n",
        "    vec = np.array([vocabulary_matrix[word2idx[w]] for w in n_grams[i]]).flatten()\n",
        "    features[i] = vec\n",
        "  \n",
        "  return features\n",
        "\n",
        "################### run it only once, load it from pickle files ##################\n",
        "# train_features = get_wordvec_features(train_n_grams)\n",
        "# test_features = get_wordvec_features(test_n_grams)\n",
        "# val_features = get_wordvec_features(val_n_grams)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx06aDWeewkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('train_features.npy', train_features)\n",
        "np.save('test_features.npy', test_features)\n",
        "np.save('val_features.npy', val_features)\n",
        "\n",
        "np.save('vocab.npy', vocabulary_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU9VAmXCkPaM",
        "colab_type": "text"
      },
      "source": [
        "# Load saved features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iczKJIrrhTh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = np.load('train_features.npy')\n",
        "test_features = np.load('test_features.npy')\n",
        "val_features = np.load('val_features.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS-bc_Y3kWIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GvFas3E0BIev",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 32\n",
        "\n",
        "\n",
        "# converting into indices\n",
        "X_train, oov_train = get_word2vec_indices(train_n_grams)\n",
        "X_val, oov_val = get_word2vec_indices(val_n_grams)\n",
        "X_test, oov_test = get_word2vec_indices(test_n_grams)\n",
        "\n",
        "# # padding with Max len = 512\n",
        "# X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value=MAX_LEN + 1)\n",
        "# X_val = pad_sequences(maxlen=MAX_LEN, sequences=X_val, padding=\"post\", value=MAX_LEN + 1)\n",
        "# X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value=MAX_LEN + 1)\n",
        "\n",
        "# converting tags to indices\n",
        "y_train = [tag2idx[w] for w in train_labels] \n",
        "y_val = [tag2idx[w] for w in val_labels]\n",
        "y_test = [tag2idx[w] for w in test_labels]\n",
        "\n",
        "\n",
        "# # padding with Max len = 512\n",
        "# y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"o\"])\n",
        "# y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"o\"])\n",
        "# y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"o\"])\n",
        "\n",
        "\n",
        "# Making labels to one hot encoded\n",
        "\n",
        "y_train = [to_categorical(i, num_classes=num_tags) for i in y_train]\n",
        "y_val = [to_categorical(i, num_classes=num_tags) for i in y_val]\n",
        "y_test = [to_categorical(i, num_classes=num_tags) for i in y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gbL8YynLp1_",
        "colab_type": "text"
      },
      "source": [
        "### Number of OOV words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAYYUCLi8gZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"% of OOV words in train set = {oov_train/num_train}\")\n",
        "print(f\"% of OOV words in val set = {oov_val/num_val}\")\n",
        "print(f\"% of OOV words in test set = {oov_test/num_test}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4GMhul-LZ1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}