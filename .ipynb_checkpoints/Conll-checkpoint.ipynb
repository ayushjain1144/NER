{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCIhRSJdTa4n"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcnW6tZ9NcxR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NmeeldkNqYp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-675a66e932c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from gensim import models\n",
    "import copy\n",
    "import os\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5gGwn4eTemk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###### Keras module is only used for PREPROCESSING not TRAINING ######\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-x1ZDqNcNyu"
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# n gram model  = 2 * C + 1\n",
    "C = 1\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hv4nKMQnTClV"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNka7S4aS5n3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ayushjain1144/New Linux/NER\n",
      "activations.py\t\t  loss.py\t\ttest_features.npy\n",
      "Conll.ipynb\t\t  NER_NN.ipynb\t\ttrain_features.npy\n",
      "dataset\t\t\t  NER_NN_network.ipynb\tval_features.npy\n",
      "initial_experiment.ipynb  nn.py\t\t\tvocab.npy\n",
      "initialization.py\t  README.md\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ko7FngSbUzpo"
   },
   "outputs": [],
   "source": [
    "dataset_base_dir = './dataset/'\n",
    "train_data_file = os.path.join(dataset_base_dir, 'train.txt')\n",
    "val_data_file = os.path.join(dataset_base_dir, 'valid.txt')\n",
    "test_data_file = os.path.join(dataset_base_dir, 'test.txt')\n",
    "\n",
    "train_data = open(train_data_file, 'r').read().lower()\n",
    "test_data = open(test_data_file, 'r').read().lower()\n",
    "val_data = open(val_data_file, 'r').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIFbfG5WViBq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "EU NNP B-NP B-ORG\r\n",
      "rejects VBZ B-VP O\r\n",
      "German JJ B-NP B-MISC\r\n",
      "call NN I-NP O\r\n",
      "to TO B-VP O\r\n",
      "boycott VB I-VP O\r\n",
      "British JJ B-NP B-MISC\r\n",
      "lamb NN I-NP O\r\n",
      ". . O O\r\n",
      "\r\n",
      "Peter NNP B-NP B-PER\r\n",
      "Blackburn NNP I-NP I-PER\r\n",
      "\r\n",
      "BRUSSELS NNP B-NP B-LOC\r\n",
      "1996-08-22 CD I-NP O\r\n",
      "\r\n",
      "The DT B-NP O\r\n",
      "European NNP I-NP B-ORG\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 dataset/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VO8HVgOXV4Sr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "SOCCER NN B-NP O\r\n",
      "- : O O\r\n",
      "JAPAN NNP B-NP B-LOC\r\n",
      "GET VB B-VP O\r\n",
      "LUCKY NNP B-NP O\r\n",
      "WIN NNP I-NP O\r\n",
      ", , O O\r\n",
      "CHINA NNP B-NP B-PER\r\n",
      "IN IN B-PP O\r\n",
      "SURPRISE DT B-NP O\r\n",
      "DEFEAT NN I-NP O\r\n",
      ". . O O\r\n",
      "\r\n",
      "Nadim NNP B-NP B-PER\r\n",
      "Ladki NNP I-NP I-PER\r\n",
      "\r\n",
      "AL-AIN NNP B-NP B-LOC\r\n",
      ", , O O\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 dataset/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnGBCrANWACB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "CRICKET NNP B-NP O\r\n",
      "- : O O\r\n",
      "LEICESTERSHIRE NNP B-NP B-ORG\r\n",
      "TAKE NNP I-NP O\r\n",
      "OVER IN B-PP O\r\n",
      "AT NNP B-NP O\r\n",
      "TOP NNP I-NP O\r\n",
      "AFTER NNP I-NP O\r\n",
      "INNINGS NNP I-NP O\r\n",
      "VICTORY NN I-NP O\r\n",
      ". . O O\r\n",
      "\r\n",
      "LONDON NNP B-NP B-LOC\r\n",
      "1996-08-30 CD I-NP O\r\n",
      "\r\n",
      "West NNP B-NP B-MISC\r\n",
      "Indian NNP I-NP I-MISC\r\n",
      "all-rounder NN I-NP O\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 dataset/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUVhTDgnWehq"
   },
   "outputs": [],
   "source": [
    "TRAINDATA = StringIO(train_data)\n",
    "\n",
    "train_df = pd.read_csv(TRAINDATA, sep=\" \", header=None)\n",
    "train_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
    "train_df = train_df[1:]\n",
    "\n",
    "TESTDATA = StringIO(test_data)\n",
    "test_df = pd.read_csv(TESTDATA, sep=\" \", header=None)\n",
    "test_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
    "test_df = test_df[1:]\n",
    "\n",
    "VALDATA = StringIO(val_data)\n",
    "val_df = pd.read_csv(VALDATA, sep=\" \", header=None)\n",
    "val_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
    "val_df = val_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9RUEJLld9U5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>farm</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ministers</td>\n",
       "      <td>nns</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>'</td>\n",
       "      <td>pos</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>meeting</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>of</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>causing</td>\n",
       "      <td>vbg</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>unjustified</td>\n",
       "      <td>jj</td>\n",
       "      <td>b-adjp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>alarm</td>\n",
       "      <td>nn</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>through</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>jj</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>generalisation</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>only</td>\n",
       "      <td>rb</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>france</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>b-loc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>britain</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>b-loc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>backed</td>\n",
       "      <td>vbd</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>fischler</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>'s</td>\n",
       "      <td>pos</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>proposal</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>the</td>\n",
       "      <td>dt</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>eu</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>'s</td>\n",
       "      <td>pos</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>scientific</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>veterinary</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>multidisciplinary</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>committees</td>\n",
       "      <td>nns</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>are</td>\n",
       "      <td>vbp</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>due</td>\n",
       "      <td>jj</td>\n",
       "      <td>b-adjp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>re-examine</td>\n",
       "      <td>vb</td>\n",
       "      <td>i-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>the</td>\n",
       "      <td>dt</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>issue</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>early</td>\n",
       "      <td>rb</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>next</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>month</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>make</td>\n",
       "      <td>vb</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>nns</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>the</td>\n",
       "      <td>dt</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>senior</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>veterinary</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>officials</td>\n",
       "      <td>nns</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word pos_tag chunk_tag NER_tag\n",
       "251               farm      nn      i-np       o\n",
       "252          ministers     nns      i-np       o\n",
       "253                  '     pos      b-np       o\n",
       "254            meeting      nn      i-np       o\n",
       "255                 of      in      b-pp       o\n",
       "256            causing     vbg      b-vp       o\n",
       "257        unjustified      jj    b-adjp       o\n",
       "258              alarm      nn      b-np       o\n",
       "259            through      in      b-pp       o\n",
       "260                          o         o     NaN\n",
       "261          dangerous      jj      b-np       o\n",
       "262     generalisation      nn      i-np       o\n",
       "263                  .       .         o       o\n",
       "264                          o         o     NaN\n",
       "265                  .       .         o       o\n",
       "266               only      rb      b-np       o\n",
       "267             france     nnp      i-np   b-loc\n",
       "268                and      cc      i-np       o\n",
       "269            britain     nnp      i-np   b-loc\n",
       "270             backed     vbd      b-vp       o\n",
       "271           fischler     nnp      b-np   b-per\n",
       "272                 's     pos      b-np       o\n",
       "273           proposal      nn      i-np       o\n",
       "274                  .       .         o       o\n",
       "275                the      dt      b-np       o\n",
       "276                 eu     nnp      i-np   b-org\n",
       "277                 's     pos      b-np       o\n",
       "278         scientific      jj      i-np       o\n",
       "279         veterinary      jj      i-np       o\n",
       "280                and      cc      i-np       o\n",
       "281  multidisciplinary      jj      i-np       o\n",
       "282         committees     nns      i-np       o\n",
       "283                are     vbp      b-vp       o\n",
       "284                due      jj    b-adjp       o\n",
       "285                 to      to      b-vp       o\n",
       "286         re-examine      vb      i-vp       o\n",
       "287                the      dt      b-np       o\n",
       "288              issue      nn      i-np       o\n",
       "289              early      rb      b-np       o\n",
       "290               next      jj      i-np       o\n",
       "291              month      nn      i-np       o\n",
       "292                and      cc         o       o\n",
       "293               make      vb      b-vp       o\n",
       "294    recommendations     nns      b-np       o\n",
       "295                 to      to      b-pp       o\n",
       "296                the      dt      b-np       o\n",
       "297             senior      jj      i-np       o\n",
       "298         veterinary      jj      i-np       o\n",
       "299          officials     nns      i-np       o\n",
       "300                  .       .         o       o"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[250:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI34wYUQiJr7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soccer</td>\n",
       "      <td>nn</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>japan</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-loc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get</td>\n",
       "      <td>vb</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lucky</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word pos_tag chunk_tag NER_tag\n",
       "1  soccer      nn      b-np       o\n",
       "2       -       :         o       o\n",
       "3   japan     nnp      b-np   b-loc\n",
       "4     get      vb      b-vp       o\n",
       "5   lucky     nnp      b-np       o"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Kpe0Nk5O-VA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cricket</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leicestershire</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word pos_tag chunk_tag NER_tag\n",
       "1         cricket     nnp      b-np       o\n",
       "2               -       :         o       o\n",
       "3  leicestershire     nnp      b-np   b-org\n",
       "4            take     nnp      i-np       o\n",
       "5            over      in      b-pp       o"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUrLZyDuc_Ms"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138    o\n",
       "1160    o\n",
       "1164    o\n",
       "1192    o\n",
       "1239    o\n",
       "Name: pos_tag, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This means that our model needs to predict NULL as named entity recognition\n",
    "\n",
    "val_df[val_df.isnull().any(axis=1)][\"pos_tag\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S59BcROOAiIR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75     o\n",
       "93     o\n",
       "260    o\n",
       "264    o\n",
       "366    o\n",
       "Name: pos_tag, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.isnull().any(axis=1)][\"pos_tag\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tj0KHCiXBGgF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7iJJstD3ggSR"
   },
   "outputs": [],
   "source": [
    "train_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
    "test_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
    "val_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
    "# train_df[train_df['NER_tag'] == 'no_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4boZP1SgwoF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cricket</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leicestershire</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51573</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51574</th>\n",
       "      <td>--</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51575</th>\n",
       "      <td>dhaka</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>newsroom</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>i-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51577</th>\n",
       "      <td>880-2-506363</td>\n",
       "      <td>cd</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word pos_tag chunk_tag NER_tag\n",
       "1             cricket     nnp      b-np       o\n",
       "2                   -       :         o       o\n",
       "3      leicestershire     nnp      b-np   b-org\n",
       "4                take     nnp      i-np       o\n",
       "5                over      in      b-pp       o\n",
       "...               ...     ...       ...     ...\n",
       "51573               .       .         o       o\n",
       "51574              --       :         o       o\n",
       "51575           dhaka     nnp      b-np   b-org\n",
       "51576        newsroom     nnp      i-np   i-org\n",
       "51577    880-2-506363      cd      i-np       o\n",
       "\n",
       "[51577 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dropna()\n",
    "test_df.dropna()\n",
    "val_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHEifUShLJNn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204566"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qpl50_V-Uzmp"
   },
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dm-eSZQuPBpX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 26872\n",
      "Unique Ner Tags: ['b-per', 'o', 'i-loc', 'b-org', 'b-loc', 'i-org', 'i-misc', 'i-per', 'b-misc', 'no_tag'], number: 10\n"
     ]
    }
   ],
   "source": [
    "num_train = train_df.shape[0]\n",
    "num_val = val_df.shape[0]\n",
    "num_test = test_df.shape[0]\n",
    "\n",
    "train_word_set = set(train_df[\"word\"].to_list())\n",
    "test_word_set = set(test_df[\"word\"].to_list())\n",
    "val_word_set = set(val_df[\"word\"].to_list())\n",
    "\n",
    "word_set = train_word_set.union(test_word_set, val_word_set)\n",
    "word_list = list(word_set)\n",
    "word_list.extend(['start_tk', 'end_tk'])\n",
    "print(f\"Total unique words: {len(word_list)}\")\n",
    "\n",
    "ner_tags_list = list(set(train_df['NER_tag'].to_list()))\n",
    "print(f\"Unique Ner Tags: {ner_tags_list}, number: {len(ner_tags_list)}\")\n",
    "\n",
    "num_words = len(word_list)\n",
    "num_tags = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBrzuz-LQQL6"
   },
   "outputs": [],
   "source": [
    "# convering the string data to indices dictionary\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(word_list)}\n",
    "tag2idx = {t: i for i, t in enumerate(ner_tags_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5T6lnnyVBOt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b-per': 0,\n",
       " 'o': 1,\n",
       " 'i-loc': 2,\n",
       " 'b-org': 3,\n",
       " 'b-loc': 4,\n",
       " 'i-org': 5,\n",
       " 'i-misc': 6,\n",
       " 'i-per': 7,\n",
       " 'b-misc': 8,\n",
       " 'no_tag': 9}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEjJ0Q9kgCSI",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: 0,\n",
       " 'reminds': 1,\n",
       " 'modern': 2,\n",
       " 'tons': 3,\n",
       " 'novels': 4,\n",
       " 'live': 5,\n",
       " 'buducnost': 6,\n",
       " 'branko': 7,\n",
       " 'pessimism': 8,\n",
       " 'high-priced': 9,\n",
       " 'probe': 10,\n",
       " 'totally': 11,\n",
       " 'abduction': 12,\n",
       " '506': 13,\n",
       " 'amusement': 14,\n",
       " 'compensation': 15,\n",
       " '270': 16,\n",
       " 'dietzsch': 17,\n",
       " 'treated': 18,\n",
       " 'arafat': 19,\n",
       " 'jilani': 20,\n",
       " 'rodrigo': 21,\n",
       " 'bbc': 22,\n",
       " 'maybank': 23,\n",
       " 'correct': 24,\n",
       " '3.67': 25,\n",
       " 'kerdos': 26,\n",
       " 'coach': 27,\n",
       " 'hourly': 28,\n",
       " 'sacked': 29,\n",
       " 'claude': 30,\n",
       " '7546': 31,\n",
       " 'brechu': 32,\n",
       " 'vaccari': 33,\n",
       " 'through': 34,\n",
       " 'fair': 35,\n",
       " 'derrick': 36,\n",
       " 'vestige': 37,\n",
       " 'uptrend': 38,\n",
       " 'outscoring': 39,\n",
       " 'apr-sept': 40,\n",
       " 'resolutions': 41,\n",
       " 'acceptances': 42,\n",
       " 'afash': 43,\n",
       " 'civic': 44,\n",
       " 'bancorp': 45,\n",
       " 'barge': 46,\n",
       " '5': 47,\n",
       " '152': 48,\n",
       " 'teak': 49,\n",
       " 'women': 50,\n",
       " 'sang': 51,\n",
       " 'tonnes': 52,\n",
       " 'cheaply': 53,\n",
       " 'glamorgan': 54,\n",
       " 'weather': 55,\n",
       " 'mandarin': 56,\n",
       " 'encounter': 57,\n",
       " 'bunds': 58,\n",
       " '44.2': 59,\n",
       " 'hook': 60,\n",
       " 't.': 61,\n",
       " 'swastika-covered': 62,\n",
       " 'denied': 63,\n",
       " 'enzo': 64,\n",
       " 'marc-vivien': 65,\n",
       " 'yasunori': 66,\n",
       " 'inserts': 67,\n",
       " 'padres': 68,\n",
       " 'added': 69,\n",
       " 'stream': 70,\n",
       " 'carole': 71,\n",
       " '54,703.0': 72,\n",
       " '3-78': 73,\n",
       " '21-18': 74,\n",
       " 'howley': 75,\n",
       " 'largest': 76,\n",
       " '2.240': 77,\n",
       " 'seven-point': 78,\n",
       " 'region': 79,\n",
       " '210,683': 80,\n",
       " 'bayerische': 81,\n",
       " 'money': 82,\n",
       " 'recall': 83,\n",
       " '5,710.53': 84,\n",
       " '.452': 85,\n",
       " 'croatians': 86,\n",
       " 'bordeaux': 87,\n",
       " 'watermelon': 88,\n",
       " 'gillian': 89,\n",
       " 'emon': 90,\n",
       " '690,000': 91,\n",
       " 'khalq': 92,\n",
       " 'retrieve': 93,\n",
       " 'dehydration': 94,\n",
       " 'markings': 95,\n",
       " 'bulgarians': 96,\n",
       " '199,900': 97,\n",
       " '831.40': 98,\n",
       " '9.77': 99,\n",
       " 'god': 100,\n",
       " '23.02': 101,\n",
       " 'pose': 102,\n",
       " 'trnava': 103,\n",
       " 'sabotzik': 104,\n",
       " 'corresponds': 105,\n",
       " 'chair': 106,\n",
       " 'shape': 107,\n",
       " '21.0': 108,\n",
       " 'al-risala': 109,\n",
       " '.437': 110,\n",
       " 'recounts': 111,\n",
       " 'molenbeek': 112,\n",
       " 'skiing-officials': 113,\n",
       " 'rainbow': 114,\n",
       " 'downstairs': 115,\n",
       " 'giovanni': 116,\n",
       " 'bombings': 117,\n",
       " 'jammed': 118,\n",
       " 'aylum': 119,\n",
       " 'hamid': 120,\n",
       " '6-3': 121,\n",
       " 'rao': 122,\n",
       " '74,600': 123,\n",
       " '304': 124,\n",
       " '43rd': 125,\n",
       " 'nerves': 126,\n",
       " 'irani': 127,\n",
       " 'gets': 128,\n",
       " 'hendro': 129,\n",
       " '289.1': 130,\n",
       " 'jahan': 131,\n",
       " 'lanarkshire': 132,\n",
       " '75.8': 133,\n",
       " 'campora': 134,\n",
       " 'former': 135,\n",
       " 'modernization': 136,\n",
       " 'evening': 137,\n",
       " 'debates': 138,\n",
       " 'coerced': 139,\n",
       " 'orphan': 140,\n",
       " 'revived': 141,\n",
       " '8.00': 142,\n",
       " 'gurion': 143,\n",
       " 'nucleus': 144,\n",
       " 'iraq': 145,\n",
       " '2,232': 146,\n",
       " 'prosecutors': 147,\n",
       " 'non-medicare': 148,\n",
       " 'indiana': 149,\n",
       " 'conc': 150,\n",
       " '229': 151,\n",
       " 'fringe': 152,\n",
       " 'chirac': 153,\n",
       " 'passes': 154,\n",
       " 'w-4': 155,\n",
       " 'ends': 156,\n",
       " 'complete': 157,\n",
       " 'housewares': 158,\n",
       " 'prichard': 159,\n",
       " 'dutch': 160,\n",
       " \"t.o'gorman\": 161,\n",
       " 'army-backed': 162,\n",
       " 'khaled': 163,\n",
       " 'goma-bukavu': 164,\n",
       " 'radnicki': 165,\n",
       " 'begging': 166,\n",
       " 'position-squaring': 167,\n",
       " 'founded': 168,\n",
       " 'drought': 169,\n",
       " 'mg-technogym': 170,\n",
       " 'kay': 171,\n",
       " 'polti': 172,\n",
       " 'boyd': 173,\n",
       " 'dirty': 174,\n",
       " '48.2': 175,\n",
       " 'failure': 176,\n",
       " 'priorities': 177,\n",
       " 'french-owned': 178,\n",
       " '33969650': 179,\n",
       " 'shivnarine': 180,\n",
       " 'overdone': 181,\n",
       " 'medved': 182,\n",
       " 'principally': 183,\n",
       " 'robberies': 184,\n",
       " 'camat': 185,\n",
       " 'gajduskova': 186,\n",
       " 'cesar': 187,\n",
       " 'preliminary': 188,\n",
       " 'patriarch': 189,\n",
       " 'bridge': 190,\n",
       " 'rabbani': 191,\n",
       " '125,000': 192,\n",
       " 'anti-': 193,\n",
       " 'duties': 194,\n",
       " 'canonica': 195,\n",
       " '.519': 196,\n",
       " 'financial': 197,\n",
       " 'drive': 198,\n",
       " 'invited': 199,\n",
       " 'head-butt': 200,\n",
       " 'pyramid': 201,\n",
       " 'indifference': 202,\n",
       " 'saimir': 203,\n",
       " 'renshaw': 204,\n",
       " 'franked': 205,\n",
       " 'practical': 206,\n",
       " 'capacity': 207,\n",
       " 'tomasson': 208,\n",
       " '1966': 209,\n",
       " 'ropelines': 210,\n",
       " 'wath': 211,\n",
       " 'syria': 212,\n",
       " 'ballots': 213,\n",
       " '77.5': 214,\n",
       " '1.55': 215,\n",
       " 'inga': 216,\n",
       " 'straddles': 217,\n",
       " 'larry': 218,\n",
       " '355,900': 219,\n",
       " 'tarnished': 220,\n",
       " 'canyon': 221,\n",
       " 'moisture': 222,\n",
       " 'evasion': 223,\n",
       " 'pga': 224,\n",
       " 'margaret': 225,\n",
       " 'writer': 226,\n",
       " 'ivory': 227,\n",
       " 'licences': 228,\n",
       " 'asmara': 229,\n",
       " 'raja': 230,\n",
       " 'acc': 231,\n",
       " 'extorted': 232,\n",
       " 'lahssini': 233,\n",
       " '.446': 234,\n",
       " '+15,272': 235,\n",
       " 'bone': 236,\n",
       " 'slum': 237,\n",
       " 'bernhard': 238,\n",
       " 'square-jawed': 239,\n",
       " 'loans': 240,\n",
       " '37-year': 241,\n",
       " 'lahore': 242,\n",
       " 'treats': 243,\n",
       " 'tempest': 244,\n",
       " 'nallbani': 245,\n",
       " '53.01': 246,\n",
       " 'foreldorado': 247,\n",
       " 'nottingham': 248,\n",
       " 'way': 249,\n",
       " 'pat': 250,\n",
       " '15-month': 251,\n",
       " 'detained': 252,\n",
       " '9.33': 253,\n",
       " 'aa-': 254,\n",
       " 'mcnulty': 255,\n",
       " 'damion': 256,\n",
       " 'kuttner': 257,\n",
       " 'saad': 258,\n",
       " 'a380': 259,\n",
       " 'peggy': 260,\n",
       " '9-276': 261,\n",
       " 'jail': 262,\n",
       " '38': 263,\n",
       " 'cif': 264,\n",
       " 'earned': 265,\n",
       " 'ilir': 266,\n",
       " '1-22': 267,\n",
       " 'fifteen': 268,\n",
       " 'invalidated': 269,\n",
       " 'then': 270,\n",
       " 'lowering': 271,\n",
       " 'medallist': 272,\n",
       " 'verdict': 273,\n",
       " '....': 274,\n",
       " 'rarely-traded': 275,\n",
       " '41.0-42.5': 276,\n",
       " 'adults': 277,\n",
       " 'munk': 278,\n",
       " 'disapproved': 279,\n",
       " 'atwood': 280,\n",
       " 'jas': 281,\n",
       " 'hartford': 282,\n",
       " 'molata': 283,\n",
       " 'solitary': 284,\n",
       " 'carrier': 285,\n",
       " 'vatican': 286,\n",
       " 'integrity': 287,\n",
       " 'dispatch': 288,\n",
       " 'joey': 289,\n",
       " 'mandela': 290,\n",
       " 'td': 291,\n",
       " 'billionaire': 292,\n",
       " 'nablus': 293,\n",
       " '7.5': 294,\n",
       " 'gender': 295,\n",
       " 'cab': 296,\n",
       " 'ringed': 297,\n",
       " 'fiercely': 298,\n",
       " '234,330': 299,\n",
       " 'sbf-120': 300,\n",
       " '1,141.50': 301,\n",
       " 'priced': 302,\n",
       " 'four-decade': 303,\n",
       " '1:55.281': 304,\n",
       " 'blume': 305,\n",
       " 'kovacs': 306,\n",
       " 'soccer': 307,\n",
       " '12.00': 308,\n",
       " '96.78': 309,\n",
       " 'guidance': 310,\n",
       " 'bails': 311,\n",
       " 'havre': 312,\n",
       " '8:00': 313,\n",
       " 'stich': 314,\n",
       " 'konterman': 315,\n",
       " 'tripoli': 316,\n",
       " '60-year-old': 317,\n",
       " 'konga': 318,\n",
       " 'low-margin': 319,\n",
       " 'sprint': 320,\n",
       " 'water-carrier': 321,\n",
       " 'reuter': 322,\n",
       " 'sometime': 323,\n",
       " 'progressively': 324,\n",
       " 'constraints': 325,\n",
       " '10-1-39-1': 326,\n",
       " '38.05': 327,\n",
       " 'bureaucracy': 328,\n",
       " 'ayodhya': 329,\n",
       " 'mendy': 330,\n",
       " 'detainees': 331,\n",
       " 'ambiguous': 332,\n",
       " 'goschen': 333,\n",
       " 'pensioner': 334,\n",
       " 'spitzbergen': 335,\n",
       " 'jomhuri': 336,\n",
       " 'maul': 337,\n",
       " 'angered': 338,\n",
       " 'dugmore': 339,\n",
       " '.595': 340,\n",
       " \"'s\": 341,\n",
       " 'gos': 342,\n",
       " 'container': 343,\n",
       " 'frantically': 344,\n",
       " 'publicity': 345,\n",
       " 'jyvasklya': 346,\n",
       " 'near-term': 347,\n",
       " 'dropping': 348,\n",
       " 'hesitate': 349,\n",
       " '48th': 350,\n",
       " '8.62': 351,\n",
       " 'half-time': 352,\n",
       " 'cy': 353,\n",
       " 'martin': 354,\n",
       " 'armenians': 355,\n",
       " 'mid-mississippi': 356,\n",
       " 'landslide': 357,\n",
       " 'recounted': 358,\n",
       " 'sight': 359,\n",
       " 'fairmont': 360,\n",
       " '800,000': 361,\n",
       " 'hendry': 362,\n",
       " '1069.6': 363,\n",
       " 'disappointment': 364,\n",
       " 'terrified': 365,\n",
       " 'victory': 366,\n",
       " 'harper-collins': 367,\n",
       " 'monde': 368,\n",
       " 'promoting': 369,\n",
       " '110.50': 370,\n",
       " 'loudness': 371,\n",
       " 'rapists': 372,\n",
       " 'fading': 373,\n",
       " 'kidding': 374,\n",
       " 'lenders': 375,\n",
       " 'sjeng': 376,\n",
       " 'uzi': 377,\n",
       " 'folded': 378,\n",
       " 'mostly': 379,\n",
       " '0.42': 380,\n",
       " '1853': 381,\n",
       " 'third-round': 382,\n",
       " 'intestine': 383,\n",
       " 'developers': 384,\n",
       " 'defined': 385,\n",
       " 'suraj': 386,\n",
       " 'chiappa': 387,\n",
       " '9-153': 388,\n",
       " 'gert': 389,\n",
       " 'reformist': 390,\n",
       " '9-10': 391,\n",
       " 'semis': 392,\n",
       " 'subpoenaed': 393,\n",
       " '69,252': 394,\n",
       " 'coverable': 395,\n",
       " 'paceman': 396,\n",
       " 'dini': 397,\n",
       " 'weigh': 398,\n",
       " 'langmore': 399,\n",
       " '20.54': 400,\n",
       " '3-125': 401,\n",
       " '1-11': 402,\n",
       " 'ernst': 403,\n",
       " '3:45.061': 404,\n",
       " 'sickened': 405,\n",
       " '16=': 406,\n",
       " 'a.': 407,\n",
       " 'otherwise': 408,\n",
       " '62': 409,\n",
       " 'contests': 410,\n",
       " 'kevic': 411,\n",
       " '40-0': 412,\n",
       " 'fate': 413,\n",
       " 'heath': 414,\n",
       " 'brabham': 415,\n",
       " 'nichols': 416,\n",
       " 'gavaldon': 417,\n",
       " '561': 418,\n",
       " 'brain-wasting': 419,\n",
       " 'sava': 420,\n",
       " 'montillet': 421,\n",
       " 'roque': 422,\n",
       " 'zabrze': 423,\n",
       " '0.79': 424,\n",
       " 'luis': 425,\n",
       " 'moments': 426,\n",
       " '1-3/4': 427,\n",
       " 'exact': 428,\n",
       " '72.07': 429,\n",
       " 'mok': 430,\n",
       " 'three-term': 431,\n",
       " 'acquire': 432,\n",
       " 'necaxa': 433,\n",
       " 'louder': 434,\n",
       " 'palmans': 435,\n",
       " 'holes': 436,\n",
       " 'decades': 437,\n",
       " 'having': 438,\n",
       " 'hines': 439,\n",
       " 'peter': 440,\n",
       " 'southeastern': 441,\n",
       " 'reconsider': 442,\n",
       " 'exxon': 443,\n",
       " 'hk': 444,\n",
       " 'conversation': 445,\n",
       " 'pau-orthez': 446,\n",
       " 'alexander': 447,\n",
       " 'replaced': 448,\n",
       " 'pharmaceutical': 449,\n",
       " 'astrologer': 450,\n",
       " 'cairo': 451,\n",
       " '0.9': 452,\n",
       " 'cairns': 453,\n",
       " 'ballace': 454,\n",
       " 'card': 455,\n",
       " 'spitz': 456,\n",
       " 'levingston': 457,\n",
       " 'happen': 458,\n",
       " 'kazan': 459,\n",
       " 'democracy': 460,\n",
       " '2,563.16': 461,\n",
       " '2,146.79': 462,\n",
       " 'predictable': 463,\n",
       " '2-38': 464,\n",
       " 'painful': 465,\n",
       " 'thumbnail': 466,\n",
       " 'receding': 467,\n",
       " 'sixty': 468,\n",
       " 'g': 469,\n",
       " 'five-match': 470,\n",
       " 'titanic': 471,\n",
       " 'revisions': 472,\n",
       " 'pro-rated': 473,\n",
       " 'drifted': 474,\n",
       " '0.30': 475,\n",
       " 'defending': 476,\n",
       " 'pooling-of-interest': 477,\n",
       " 'pardon': 478,\n",
       " 'erzincan': 479,\n",
       " '+353': 480,\n",
       " 'cede': 481,\n",
       " 'anto': 482,\n",
       " '53.20': 483,\n",
       " 'ratification': 484,\n",
       " 'university': 485,\n",
       " 'agyepong': 486,\n",
       " 'solo': 487,\n",
       " 'bredesen': 488,\n",
       " 'obsession': 489,\n",
       " '21.625': 490,\n",
       " 'follows': 491,\n",
       " 'cannon': 492,\n",
       " '**': 493,\n",
       " 'positively': 494,\n",
       " 'andrei': 495,\n",
       " 'alliance-menatep': 496,\n",
       " 'atagi': 497,\n",
       " 'brutally': 498,\n",
       " 'conservative': 499,\n",
       " 'insistent': 500,\n",
       " '8.03': 501,\n",
       " 'circumstances': 502,\n",
       " 'stewart': 503,\n",
       " 'denote': 504,\n",
       " 'laban': 505,\n",
       " 'kennet': 506,\n",
       " 'rely': 507,\n",
       " 'han': 508,\n",
       " 'bringing': 509,\n",
       " 'committing': 510,\n",
       " 'forest': 511,\n",
       " '17,844': 512,\n",
       " 'ram': 513,\n",
       " 'hambrecht': 514,\n",
       " \"mar'ie\": 515,\n",
       " 'rfdg': 516,\n",
       " 'state-by-state': 517,\n",
       " 'reserved': 518,\n",
       " 'avellino': 519,\n",
       " 'golfers': 520,\n",
       " 'wilderness': 521,\n",
       " 'portadown': 522,\n",
       " 'parma': 523,\n",
       " 'sheriff': 524,\n",
       " '64.73': 525,\n",
       " '59.50': 526,\n",
       " '965m': 527,\n",
       " 'shortly': 528,\n",
       " '7-2-11-0': 529,\n",
       " 'mckiernan': 530,\n",
       " 'lacklustre': 531,\n",
       " 'wean': 532,\n",
       " 'outspoken': 533,\n",
       " 'shareholers': 534,\n",
       " '13:21.35': 535,\n",
       " 'round': 536,\n",
       " '31,000': 537,\n",
       " 'juergen': 538,\n",
       " 'straight': 539,\n",
       " '6-0-26-0': 540,\n",
       " 'port': 541,\n",
       " 'collides': 542,\n",
       " 'dubai': 543,\n",
       " 'requirements': 544,\n",
       " 'upgrade': 545,\n",
       " 'participate': 546,\n",
       " '5.00': 547,\n",
       " 'header': 548,\n",
       " '76': 549,\n",
       " 'cameroon': 550,\n",
       " '92.0-94.5': 551,\n",
       " 'destocked': 552,\n",
       " 'xue': 553,\n",
       " 'rejoined': 554,\n",
       " 'makers': 555,\n",
       " 'abraham': 556,\n",
       " 'towns': 557,\n",
       " '8.63': 558,\n",
       " 'non-trade': 559,\n",
       " 'francescato': 560,\n",
       " 'apparel': 561,\n",
       " 'setttlements': 562,\n",
       " '276': 563,\n",
       " 'fay': 564,\n",
       " 'pleasant': 565,\n",
       " 'stranraer': 566,\n",
       " '7:13': 567,\n",
       " 'impetus': 568,\n",
       " 'distances': 569,\n",
       " 'serb-held': 570,\n",
       " 'camacho': 571,\n",
       " 'abortion': 572,\n",
       " 'resurgent': 573,\n",
       " 'ibrahimi': 574,\n",
       " 'q4': 575,\n",
       " 'kosgei': 576,\n",
       " 'besiktas': 577,\n",
       " 'schering': 578,\n",
       " 'abandoning': 579,\n",
       " 'infusion': 580,\n",
       " 'icac': 581,\n",
       " 'bardejov': 582,\n",
       " 'cm': 583,\n",
       " 'wounded': 584,\n",
       " 'sightings': 585,\n",
       " '.263': 586,\n",
       " '112.00': 587,\n",
       " 'chance': 588,\n",
       " 'nebraska': 589,\n",
       " 'mona': 590,\n",
       " 'dakar': 591,\n",
       " '40.7': 592,\n",
       " 'detains': 593,\n",
       " '70,848.86': 594,\n",
       " '8.18': 595,\n",
       " 'camp': 596,\n",
       " '20-30/1': 597,\n",
       " 'state': 598,\n",
       " 'anke': 599,\n",
       " 'narino': 600,\n",
       " 'encountered': 601,\n",
       " '97.82': 602,\n",
       " 'larsen': 603,\n",
       " 'border': 604,\n",
       " 'joceyln': 605,\n",
       " 'disqualified': 606,\n",
       " 'mfs': 607,\n",
       " 'arasu': 608,\n",
       " 'occasionally': 609,\n",
       " 'burden': 610,\n",
       " '389': 611,\n",
       " '8.07': 612,\n",
       " '0.042': 613,\n",
       " 'skeid': 614,\n",
       " 'caps': 615,\n",
       " 'dede': 616,\n",
       " 'taiba': 617,\n",
       " 'impede': 618,\n",
       " 'mutton': 619,\n",
       " 'jean-luc': 620,\n",
       " 'southern': 621,\n",
       " 'schwarthoff': 622,\n",
       " 'densakul': 623,\n",
       " '30.aug.96': 624,\n",
       " 'barings': 625,\n",
       " '1969': 626,\n",
       " '23/32': 627,\n",
       " 'bonds': 628,\n",
       " '1714': 629,\n",
       " 'arwel': 630,\n",
       " 'ould': 631,\n",
       " 'iscovered': 632,\n",
       " '1:51.006': 633,\n",
       " '22.56': 634,\n",
       " 'hampshire': 635,\n",
       " 'ice': 636,\n",
       " '0.08': 637,\n",
       " 'eavesdrop': 638,\n",
       " 'enchaine': 639,\n",
       " 'toledo': 640,\n",
       " 'twilight': 641,\n",
       " 'allah': 642,\n",
       " 'baja': 643,\n",
       " 'baldwin': 644,\n",
       " 'powell': 645,\n",
       " 'goals': 646,\n",
       " 'write': 647,\n",
       " 'impression': 648,\n",
       " 'ultimately': 649,\n",
       " 'ihlas': 650,\n",
       " 'seminary': 651,\n",
       " 'k.c.': 652,\n",
       " '12.50': 653,\n",
       " '0.355': 654,\n",
       " '1,433.4': 655,\n",
       " '50.574': 656,\n",
       " 'langage': 657,\n",
       " 'marines': 658,\n",
       " 'onyali': 659,\n",
       " 'itself': 660,\n",
       " 'madrid': 661,\n",
       " '.532': 662,\n",
       " 'tend': 663,\n",
       " 'unifil': 664,\n",
       " 'left-footed': 665,\n",
       " 'cvg': 666,\n",
       " 'mobutu': 667,\n",
       " 'rund': 668,\n",
       " 'looms': 669,\n",
       " 'simitis': 670,\n",
       " 'fightback': 671,\n",
       " 'babangida': 672,\n",
       " 'male': 673,\n",
       " 'luigi': 674,\n",
       " 'post-suspension': 675,\n",
       " 'headless': 676,\n",
       " 'shift': 677,\n",
       " 'ridiculed': 678,\n",
       " '97-94': 679,\n",
       " '3-116': 680,\n",
       " 'medals': 681,\n",
       " 'drove': 682,\n",
       " 'tanura': 683,\n",
       " 'nymex': 684,\n",
       " 'inter': 685,\n",
       " '284': 686,\n",
       " 'westernising': 687,\n",
       " 'wen': 688,\n",
       " 'collaborators': 689,\n",
       " 'simec': 690,\n",
       " 'responded': 691,\n",
       " 'has': 692,\n",
       " 'crr': 693,\n",
       " 'pilkington': 694,\n",
       " 'infrastructure': 695,\n",
       " 'intra-day': 696,\n",
       " '880-2-506363': 697,\n",
       " 'constructorol': 698,\n",
       " '85th': 699,\n",
       " 'spirits': 700,\n",
       " 'lumir': 701,\n",
       " 'erin': 702,\n",
       " 'commander-in-chief': 703,\n",
       " '.431': 704,\n",
       " 'foreign': 705,\n",
       " 'postponement': 706,\n",
       " 'full-year': 707,\n",
       " 'stung': 708,\n",
       " '22nd': 709,\n",
       " 'granville': 710,\n",
       " 'rebel-controlled': 711,\n",
       " 'rivals': 712,\n",
       " 'ove': 713,\n",
       " 'dudayev': 714,\n",
       " 'muni': 715,\n",
       " 'dwt': 716,\n",
       " 'dodge': 717,\n",
       " 'semerdjieva': 718,\n",
       " '7-6': 719,\n",
       " 'consistent': 720,\n",
       " 'marble': 721,\n",
       " 'jewellers': 722,\n",
       " 'assailant': 723,\n",
       " '257': 724,\n",
       " 'derailment': 725,\n",
       " 'composite': 726,\n",
       " 'practice': 727,\n",
       " 'pescara': 728,\n",
       " 'undaunted': 729,\n",
       " '187': 730,\n",
       " 'diseases': 731,\n",
       " 'sportsman': 732,\n",
       " 'el-baz': 733,\n",
       " 'xinhua': 734,\n",
       " 'electricity': 735,\n",
       " 'george': 736,\n",
       " \"d'outre\": 737,\n",
       " 'tan': 738,\n",
       " '531': 739,\n",
       " '6.65': 740,\n",
       " 'station': 741,\n",
       " 'cristofoletto': 742,\n",
       " 'po': 743,\n",
       " 'soberly': 744,\n",
       " 'janne': 745,\n",
       " 'counties': 746,\n",
       " 'londgaard': 747,\n",
       " 'proleter': 748,\n",
       " 'barrington': 749,\n",
       " 'phillies': 750,\n",
       " '204-947-3548': 751,\n",
       " '58': 752,\n",
       " 'despite': 753,\n",
       " 'rapeseed': 754,\n",
       " 'welcoming': 755,\n",
       " 'listless': 756,\n",
       " 'neutral': 757,\n",
       " 'officer': 758,\n",
       " 'troubled': 759,\n",
       " 'stretched': 760,\n",
       " 'wolf': 761,\n",
       " 'thinakaran': 762,\n",
       " 'ally': 763,\n",
       " 'retinal': 764,\n",
       " 'laughing': 765,\n",
       " 'kidnapped': 766,\n",
       " '332': 767,\n",
       " 'naberezhnye': 768,\n",
       " 'taichung': 769,\n",
       " 'pintusevich': 770,\n",
       " 'rupam': 771,\n",
       " 'documentary': 772,\n",
       " 'raith': 773,\n",
       " '85-82': 774,\n",
       " 'tauranga': 775,\n",
       " 'kersey': 776,\n",
       " 'terminated': 777,\n",
       " 'shortstop': 778,\n",
       " 'unique': 779,\n",
       " 'lb-1': 780,\n",
       " 'urus-martan': 781,\n",
       " 'laurie': 782,\n",
       " 'couterpart': 783,\n",
       " 'published': 784,\n",
       " 'embarrassing': 785,\n",
       " 'aid-u.n.': 786,\n",
       " 'evelyne': 787,\n",
       " 'nader': 788,\n",
       " 'belonging': 789,\n",
       " 'no-new-tax': 790,\n",
       " 'sunbed': 791,\n",
       " 'parade': 792,\n",
       " 'attract': 793,\n",
       " 'nb-8': 794,\n",
       " '14,153': 795,\n",
       " 'pelletreau': 796,\n",
       " 'bps': 797,\n",
       " 'berisha': 798,\n",
       " 'procedure': 799,\n",
       " 'topple': 800,\n",
       " 'molested': 801,\n",
       " '195-km': 802,\n",
       " 'vow': 803,\n",
       " 'pius': 804,\n",
       " 'kiev': 805,\n",
       " 'use': 806,\n",
       " 'zairean': 807,\n",
       " 'rushing': 808,\n",
       " 'ecu': 809,\n",
       " 'confiscated': 810,\n",
       " 'protestors': 811,\n",
       " 'disappearances': 812,\n",
       " 'alain': 813,\n",
       " 'milinko': 814,\n",
       " '1:56.286': 815,\n",
       " '202.59': 816,\n",
       " 'peso': 817,\n",
       " 'convinced': 818,\n",
       " 'vagrants': 819,\n",
       " 'minorities': 820,\n",
       " 'warehouse': 821,\n",
       " 'millns': 822,\n",
       " 'heaven': 823,\n",
       " 'locomotive': 824,\n",
       " 'handrik': 825,\n",
       " '10,650,407': 826,\n",
       " 'ottoz': 827,\n",
       " 'lingered': 828,\n",
       " '82.20': 829,\n",
       " 'enthusiast': 830,\n",
       " 'netherland': 831,\n",
       " 'patasse': 832,\n",
       " 'drafts': 833,\n",
       " 'explosives': 834,\n",
       " 'gheorghe': 835,\n",
       " 'odv': 836,\n",
       " 'words': 837,\n",
       " 'veggerby': 838,\n",
       " 'applied': 839,\n",
       " 'due': 840,\n",
       " 'forehand': 841,\n",
       " 'very': 842,\n",
       " 'development': 843,\n",
       " 'ellina': 844,\n",
       " 'afrikaans': 845,\n",
       " '10-0': 846,\n",
       " 'moreira': 847,\n",
       " '900.00': 848,\n",
       " 'gleveckas': 849,\n",
       " '469': 850,\n",
       " '15-8': 851,\n",
       " 'testing': 852,\n",
       " 'thorsten': 853,\n",
       " 'podujevo': 854,\n",
       " '391-seat': 855,\n",
       " 'hinted': 856,\n",
       " 'ranks': 857,\n",
       " 'one-two': 858,\n",
       " 'lago': 859,\n",
       " 'dividing': 860,\n",
       " 'teams': 861,\n",
       " 'fast-food': 862,\n",
       " '13.17': 863,\n",
       " 'investigating': 864,\n",
       " 'vehemently': 865,\n",
       " 'tomb': 866,\n",
       " 'biologist': 867,\n",
       " 'sukur': 868,\n",
       " 'payments': 869,\n",
       " 'baron': 870,\n",
       " 'liked': 871,\n",
       " 'shutout': 872,\n",
       " 'surabaya': 873,\n",
       " '1968': 874,\n",
       " '8.30': 875,\n",
       " '...it': 876,\n",
       " 'indelible': 877,\n",
       " 'yedioth': 878,\n",
       " 'rents': 879,\n",
       " '18.55': 880,\n",
       " 'commuted': 881,\n",
       " '50-28': 882,\n",
       " 'norbu': 883,\n",
       " 'budgeted': 884,\n",
       " 'sacking': 885,\n",
       " 'sudiriman': 886,\n",
       " 'indians': 887,\n",
       " 'lezion': 888,\n",
       " 'tipped': 889,\n",
       " 'w224': 890,\n",
       " 'bangladeshi': 891,\n",
       " 'pamir': 892,\n",
       " 'katowice': 893,\n",
       " 'soviet': 894,\n",
       " 'congo': 895,\n",
       " 'milosevic': 896,\n",
       " 'remote': 897,\n",
       " 'model': 898,\n",
       " 'doorn': 899,\n",
       " 'contractors': 900,\n",
       " 'latina': 901,\n",
       " '0.65': 902,\n",
       " 'bought': 903,\n",
       " 'slippage': 904,\n",
       " 'refiner': 905,\n",
       " 'activation': 906,\n",
       " 'moya': 907,\n",
       " 'girlfriend': 908,\n",
       " 'w145': 909,\n",
       " 'luebeck': 910,\n",
       " 'prudent': 911,\n",
       " 'tillstrom': 912,\n",
       " 'janet': 913,\n",
       " 'parts': 914,\n",
       " 'explodes': 915,\n",
       " 'mayne': 916,\n",
       " 'henry': 917,\n",
       " 'equivalents': 918,\n",
       " '850,968': 919,\n",
       " 'lift': 920,\n",
       " 'diverted': 921,\n",
       " 'staff': 922,\n",
       " 'riel': 923,\n",
       " 'diyarbakir': 924,\n",
       " 'thefts': 925,\n",
       " 'benoit': 926,\n",
       " 'seven-year-old': 927,\n",
       " 'loco': 928,\n",
       " 'andresen': 929,\n",
       " 'voorhis': 930,\n",
       " 'limited': 931,\n",
       " 'podium': 932,\n",
       " 'arms': 933,\n",
       " 'constanza': 934,\n",
       " '3.35': 935,\n",
       " 'dictatorial': 936,\n",
       " 'unflagging': 937,\n",
       " 'duct': 938,\n",
       " 'dozen': 939,\n",
       " 'filipovic': 940,\n",
       " 'homers': 941,\n",
       " 'dukla': 942,\n",
       " 'gump': 943,\n",
       " '3.75': 944,\n",
       " 'scouts': 945,\n",
       " 'smuggled': 946,\n",
       " 'drunkards': 947,\n",
       " 'colony': 948,\n",
       " 'karl': 949,\n",
       " 'indah': 950,\n",
       " 'quicken': 951,\n",
       " 'kfar': 952,\n",
       " 'cut-off-rate': 953,\n",
       " 'yunnan': 954,\n",
       " 'medical': 955,\n",
       " 'alternative': 956,\n",
       " 'handicapped': 957,\n",
       " 'policy': 958,\n",
       " '.628': 959,\n",
       " 'remarked': 960,\n",
       " 'attendence': 961,\n",
       " 'emiliano': 962,\n",
       " 'unification': 963,\n",
       " 'l.': 964,\n",
       " 'fiscal': 965,\n",
       " '2370.00': 966,\n",
       " 'mechanisms': 967,\n",
       " 'flourish': 968,\n",
       " 'ramirez': 969,\n",
       " 'lapped': 970,\n",
       " 'lukoil': 971,\n",
       " 'krejner': 972,\n",
       " '3,161': 973,\n",
       " 'final': 974,\n",
       " 'enhancement': 975,\n",
       " 'ericsson': 976,\n",
       " 'flowing': 977,\n",
       " 'blake': 978,\n",
       " 'grant': 979,\n",
       " 'disarmed': 980,\n",
       " 'e.': 981,\n",
       " 'expression': 982,\n",
       " '2.17m': 983,\n",
       " 'engulfed': 984,\n",
       " 'execution': 985,\n",
       " '1:51.075': 986,\n",
       " 'mercedes': 987,\n",
       " 'roadsides': 988,\n",
       " '29,328': 989,\n",
       " 'dnipropetrovsk': 990,\n",
       " 'flare-up': 991,\n",
       " 'step': 992,\n",
       " 'seng': 993,\n",
       " 'par-72': 994,\n",
       " 'dolphins': 995,\n",
       " 'mons': 996,\n",
       " 'assured': 997,\n",
       " '652-0642': 998,\n",
       " 'increased': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7tLFretLcYA"
   },
   "source": [
    "# Forming train and test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zK2ZiNlig9G"
   },
   "outputs": [],
   "source": [
    "def get_tagged_sentences(df):\n",
    "  tagged_list = [(w, t) for w, t in zip(df[\"word\"], df[\"NER_tag\"])]\n",
    "  final = []\n",
    "\n",
    "  for ele in tagged_list:\n",
    "\n",
    "    if not final:  # if list is empty\n",
    "      final.append([ele])\n",
    "    \n",
    "    elif final[-1][-1][0] == '.': # if the last tuple of last list is ('.', ..), form new list\n",
    "      final.append([ele])\n",
    "\n",
    "    else:       # add it to running list\n",
    "      final[-1].append(ele) \n",
    "\n",
    "  return final\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTrmpcAbQhoM"
   },
   "outputs": [],
   "source": [
    "train_sentences = get_tagged_sentences(train_df)\n",
    "test_sentences = get_tagged_sentences(test_df)\n",
    "val_sentences = get_tagged_sentences(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "El3FPswDQjm6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cricket', 'o'),\n",
       "  ('-', 'o'),\n",
       "  ('leicestershire', 'b-org'),\n",
       "  ('take', 'o'),\n",
       "  ('over', 'o'),\n",
       "  ('at', 'o'),\n",
       "  ('top', 'o'),\n",
       "  ('after', 'o'),\n",
       "  ('innings', 'o'),\n",
       "  ('victory', 'o'),\n",
       "  ('.', 'o')],\n",
       " [('london', 'b-loc'),\n",
       "  ('1996-08-30', 'o'),\n",
       "  ('west', 'b-misc'),\n",
       "  ('indian', 'i-misc'),\n",
       "  ('all-rounder', 'o'),\n",
       "  ('phil', 'b-per'),\n",
       "  ('simmons', 'i-per'),\n",
       "  ('took', 'o'),\n",
       "  ('four', 'o'),\n",
       "  ('for', 'o'),\n",
       "  ('38', 'o'),\n",
       "  ('on', 'o'),\n",
       "  ('friday', 'o'),\n",
       "  ('as', 'o'),\n",
       "  ('leicestershire', 'b-org'),\n",
       "  ('beat', 'o'),\n",
       "  ('somerset', 'b-org'),\n",
       "  ('by', 'o'),\n",
       "  ('an', 'o'),\n",
       "  ('innings', 'o'),\n",
       "  ('and', 'o'),\n",
       "  ('39', 'o'),\n",
       "  ('runs', 'o'),\n",
       "  ('in', 'o'),\n",
       "  ('two', 'o'),\n",
       "  ('days', 'o'),\n",
       "  ('to', 'o'),\n",
       "  ('take', 'o'),\n",
       "  ('over', 'o'),\n",
       "  ('at', 'o'),\n",
       "  ('the', 'o'),\n",
       "  ('head', 'o'),\n",
       "  ('of', 'o'),\n",
       "  ('the', 'o'),\n",
       "  ('county', 'o'),\n",
       "  ('championship', 'o'),\n",
       "  ('.', 'o')]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AA2mvqjLSYAp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1232"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_train = len(max(train_sentences, key=len))\n",
    "max_len_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvKmmmY1merl"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FggdzoYQijPx"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "\n",
    "# converting into indices\n",
    "X_train = [[word2idx[w[0]] for w in s] for s in train_sentences]\n",
    "X_val = [[word2idx[w[0]] for w in s] for s in val_sentences]\n",
    "X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n",
    "\n",
    "# padding with Max len = 512\n",
    "X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value=MAX_LEN + 1)\n",
    "X_val = pad_sequences(maxlen=MAX_LEN, sequences=X_val, padding=\"post\", value=MAX_LEN + 1)\n",
    "X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value=MAX_LEN + 1)\n",
    "\n",
    "# converting tags to indices\n",
    "y_train = [[tag2idx[w[1]] for w in s] for s in train_sentences]\n",
    "y_val = [[tag2idx[w[1]] for w in s] for s in val_sentences]\n",
    "y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]\n",
    "\n",
    "# padding with Max len = 512\n",
    "y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
    "y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
    "y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
    "\n",
    "\n",
    "# Making labels to one hot encoded\n",
    "\n",
    "y_train = [to_categorical(i, num_classes=num_tags) for i in y_train]\n",
    "y_val = [to_categorical(i, num_classes=num_tags) for i in y_val]\n",
    "y_test = [to_categorical(i, num_classes=num_tags) for i in y_test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BZoxsoVlB5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCxUSUY8mimK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23298,  1164,  8589,  8067,  2465,  4133, 12419, 13511, 21370,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513,   513,\n",
       "         513,   513,   513,   513,   513,   513,   513,   513],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgXQ9s5iifhH"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59XokNFVEpW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-501782d745bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Google's pretrained word2vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mword2vec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Google's pretrained word2vec model\n",
    "\n",
    "word2vec_model = models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=10 ** 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFjza2m7nCn4"
   },
   "outputs": [],
   "source": [
    "a = word2vec_model[\"computer\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ultLjMESHg6_"
   },
   "outputs": [],
   "source": [
    "# np.random.rand(*a.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHs__xXUBLSz"
   },
   "outputs": [],
   "source": [
    "def get_word2vec_indices(vocabulary):\n",
    "  \"\"\"returns wordvec index list and the number of oov words\"\"\"\n",
    "\n",
    "  vocab_matrix  = np.zeros(shape=(len(word_list), word_vector_dim))\n",
    "  oov = 0\n",
    "\n",
    "  for s, idx in vocabulary.items():\n",
    "\n",
    "    try:\n",
    "      vocab_matrix[idx] = word2vec_model[s]\n",
    "\n",
    "    except:\n",
    "      if s == 'start_tk':\n",
    "        n = np.zeros_like(a)\n",
    "        n[0] = 1\n",
    "        vocab_matrix[idx] = n\n",
    "      elif s == 'end_tk':\n",
    "        n = np.zeros_like(a)\n",
    "        n[1] = 1\n",
    "        vocab_matrix[idx] = n\n",
    "      else:\n",
    "        oov += 1\n",
    "        vocab_matrix[idx] = np.random.randn(*a.shape)\n",
    "  return vocab_matrix, oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEDtsYIQEwJ9"
   },
   "outputs": [],
   "source": [
    "vocabulary_matrix, oov = get_word2vec_indices(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncDN8YKfFJd_"
   },
   "outputs": [],
   "source": [
    "vocabulary_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpsOS1FSC8je"
   },
   "outputs": [],
   "source": [
    "n = np.zeros_like(a)\n",
    "n[0] = 1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDEQlg9JZedt"
   },
   "outputs": [],
   "source": [
    "# window size = 2 * c + 1; \n",
    "def append_start_end_marker(sentences, C=1):\n",
    "  start_set = [('start_tk', 'no_tag') for i in range(C)]\n",
    "  end_set = [('end_tk', 'no_tag') for i in range(C)]\n",
    "\n",
    "  mod_sentences = []\n",
    "  n_gram = []\n",
    "  labels = []\n",
    "  for sent in sentences:\n",
    "    mod_sentences = [ *start_set,  *sent,  *end_set]\n",
    "\n",
    "    for i in range(len(mod_sentences) - (2 * C)):\n",
    "      n_gram.append([word[0] for word in mod_sentences[i: i+ 2 * C + 1]])\n",
    "      labels.append(mod_sentences[i + C ][1])\n",
    "      \n",
    "\n",
    "  return n_gram, labels\n",
    "\n",
    "train_n_grams, train_labels = append_start_end_marker(train_sentences, C)\n",
    "test_n_grams, test_labels = append_start_end_marker(test_sentences, C)\n",
    "val_n_grams, val_labels = append_start_end_marker(val_sentences, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxWXloUlblnx"
   },
   "outputs": [],
   "source": [
    "train_n_grams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74jclUGK9Vg7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b-org',\n",
       " 'o',\n",
       " 'b-misc',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'b-misc',\n",
       " 'o',\n",
       " 'o',\n",
       " 'b-per',\n",
       " 'i-per',\n",
       " 'b-loc',\n",
       " 'o',\n",
       " 'o',\n",
       " 'b-org',\n",
       " 'i-org',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRyHH1yv9fGT"
   },
   "outputs": [],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etHDEtyqI7lp"
   },
   "outputs": [],
   "source": [
    "vocabulary_matrix[word2idx['start_tk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tF38_HJ8Ir_I"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_wordvec_features(n_grams):\n",
    "\n",
    "  features = np.zeros(shape=(len(n_grams), (2 * C + 1) * word_vector_dim))\n",
    "\n",
    "  for i in range(len(n_grams)):\n",
    "    vec = np.array([vocabulary_matrix[word2idx[w]] for w in n_grams[i]]).flatten()\n",
    "    features[i] = vec\n",
    "  \n",
    "  return features\n",
    "\n",
    "################### run it only once, load it from pickle files ##################\n",
    "# train_features = get_wordvec_features(train_n_grams)\n",
    "# test_features = get_wordvec_features(test_n_grams)\n",
    "# val_features = get_wordvec_features(val_n_grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gx06aDWeewkT"
   },
   "outputs": [],
   "source": [
    "np.save('train_features.npy', train_features)\n",
    "np.save('test_features.npy', test_features)\n",
    "np.save('val_features.npy', val_features)\n",
    "\n",
    "np.save('vocab.npy', vocabulary_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gU9VAmXCkPaM"
   },
   "source": [
    "# Load saved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iczKJIrrhTh5"
   },
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "test_features = np.load('test_features.npy')\n",
    "val_features = np.load('val_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS-bc_Y3kWIC"
   },
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvFas3E0BIev"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 32\n",
    "\n",
    "\n",
    "# converting into indices\n",
    "X_train, oov_train = get_word2vec_indices(train_n_grams)\n",
    "X_val, oov_val = get_word2vec_indices(val_n_grams)\n",
    "X_test, oov_test = get_word2vec_indices(test_n_grams)\n",
    "\n",
    "# # padding with Max len = 512\n",
    "# X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value=MAX_LEN + 1)\n",
    "# X_val = pad_sequences(maxlen=MAX_LEN, sequences=X_val, padding=\"post\", value=MAX_LEN + 1)\n",
    "# X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value=MAX_LEN + 1)\n",
    "\n",
    "# converting tags to indices\n",
    "y_train = [tag2idx[w] for w in train_labels] \n",
    "y_val = [tag2idx[w] for w in val_labels]\n",
    "y_test = [tag2idx[w] for w in test_labels]\n",
    "\n",
    "\n",
    "# # padding with Max len = 512\n",
    "# y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"o\"])\n",
    "# y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"o\"])\n",
    "# y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"o\"])\n",
    "\n",
    "\n",
    "# Making labels to one hot encoded\n",
    "\n",
    "y_train = [to_categorical(i, num_classes=num_tags) for i in y_train]\n",
    "y_val = [to_categorical(i, num_classes=num_tags) for i in y_val]\n",
    "y_test = [to_categorical(i, num_classes=num_tags) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tags to indices\n",
    "y_train = [tag2idx[w] for w in train_labels] \n",
    "y_val = [tag2idx[w] for w in val_labels]\n",
    "y_test = [tag2idx[w] for w in test_labels]\n",
    "\n",
    "\n",
    "# # padding with Max len = 512\n",
    "# y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"o\"])\n",
    "# y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"o\"])\n",
    "# y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"o\"])\n",
    "\n",
    "\n",
    "# Making labels to one hot encoded\n",
    "\n",
    "y_train = np.array([to_categorical(i, num_classes=num_tags) for i in y_train])\n",
    "y_val = np.array([to_categorical(i, num_classes=num_tags) for i in y_val])\n",
    "y_test = np.array([to_categorical(i, num_classes=num_tags) for i in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204566, 10)\n",
      "(51577, 10)\n",
      "(46665, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gbL8YynLp1_"
   },
   "source": [
    "### Number of OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAYYUCLi8gZ8"
   },
   "outputs": [],
   "source": [
    "print(f\"% of OOV words in train set = {oov_train/num_train}\")\n",
    "print(f\"% of OOV words in val set = {oov_val/num_val}\")\n",
    "print(f\"% of OOV words in test set = {oov_test/num_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4GMhul-LZ1E"
   },
   "outputs": [],
   "source": [
    "np.save('ytrain.npy', y_train)\n",
    "np.save('ytest.npy', y_test)\n",
    "np.save('yval.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgskAbjwy/JUmL99fisMrM",
   "collapsed_sections": [],
   "name": "Conll.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
