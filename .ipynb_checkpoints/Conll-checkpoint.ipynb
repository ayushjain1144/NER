{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCIhRSJdTa4n"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcnW6tZ9NcxR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tnrange\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NmeeldkNqYp"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from gensim import models\n",
    "import copy\n",
    "import os\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5gGwn4eTemk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###### Keras module is only used for PREPROCESSING not TRAINING ######\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-x1ZDqNcNyu"
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# n gram model  = 2 * C + 1\n",
    "C = 1\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hv4nKMQnTClV"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNka7S4aS5n3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ayushjain1144/New Linux/NER\n",
      "activations.py\t\t  initialization.py\tREADME.md\t    vocab.npy\n",
      "Conll.ipynb\t\t  loss.py\t\ttest_features.npy\n",
      "dataset\t\t\t  NER_NN_network.ipynb\ttrain_features.npy\n",
      "initial_experiment.ipynb  nn.py\t\t\tval_features.npy\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ko7FngSbUzpo"
   },
   "outputs": [],
   "source": [
    "dataset_base_dir = './dataset/'\n",
    "train_data_file = os.path.join(dataset_base_dir, 'train.txt')\n",
    "val_data_file = os.path.join(dataset_base_dir, 'valid.txt')\n",
    "test_data_file = os.path.join(dataset_base_dir, 'test.txt')\n",
    "\n",
    "train_data = open(train_data_file, 'r').read().lower()\n",
    "test_data = open(test_data_file, 'r').read().lower()\n",
    "val_data = open(val_data_file, 'r').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gIFbfG5WViBq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "EU NNP B-NP B-ORG\r\n",
      "rejects VBZ B-VP O\r\n",
      "German JJ B-NP B-MISC\r\n",
      "call NN I-NP O\r\n",
      "to TO B-VP O\r\n",
      "boycott VB I-VP O\r\n",
      "British JJ B-NP B-MISC\r\n",
      "lamb NN I-NP O\r\n",
      ". . O O\r\n",
      "\r\n",
      "Peter NNP B-NP B-PER\r\n",
      "Blackburn NNP I-NP I-PER\r\n",
      "\r\n",
      "BRUSSELS NNP B-NP B-LOC\r\n",
      "1996-08-22 CD I-NP O\r\n",
      "\r\n",
      "The DT B-NP O\r\n",
      "European NNP I-NP B-ORG\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 dataset/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VO8HVgOXV4Sr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "SOCCER NN B-NP O\r\n",
      "- : O O\r\n",
      "JAPAN NNP B-NP B-LOC\r\n",
      "GET VB B-VP O\r\n",
      "LUCKY NNP B-NP O\r\n",
      "WIN NNP I-NP O\r\n",
      ", , O O\r\n",
      "CHINA NNP B-NP B-PER\r\n",
      "IN IN B-PP O\r\n",
      "SURPRISE DT B-NP O\r\n",
      "DEFEAT NN I-NP O\r\n",
      ". . O O\r\n",
      "\r\n",
      "Nadim NNP B-NP B-PER\r\n",
      "Ladki NNP I-NP I-PER\r\n",
      "\r\n",
      "AL-AIN NNP B-NP B-LOC\r\n",
      ", , O O\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 dataset/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RnGBCrANWACB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "CRICKET NNP B-NP O\r\n",
      "- : O O\r\n",
      "LEICESTERSHIRE NNP B-NP B-ORG\r\n",
      "TAKE NNP I-NP O\r\n",
      "OVER IN B-PP O\r\n",
      "AT NNP B-NP O\r\n",
      "TOP NNP I-NP O\r\n",
      "AFTER NNP I-NP O\r\n",
      "INNINGS NNP I-NP O\r\n",
      "VICTORY NN I-NP O\r\n",
      ". . O O\r\n",
      "\r\n",
      "LONDON NNP B-NP B-LOC\r\n",
      "1996-08-30 CD I-NP O\r\n",
      "\r\n",
      "West NNP B-NP B-MISC\r\n",
      "Indian NNP I-NP I-MISC\r\n",
      "all-rounder NN I-NP O\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 dataset/valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUVhTDgnWehq"
   },
   "outputs": [],
   "source": [
    "TRAINDATA = StringIO(train_data)\n",
    "\n",
    "train_df = pd.read_csv(TRAINDATA, sep=\" \", header=None)\n",
    "train_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
    "train_df = train_df[1:]\n",
    "\n",
    "TESTDATA = StringIO(test_data)\n",
    "test_df = pd.read_csv(TESTDATA, sep=\" \", header=None)\n",
    "test_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
    "test_df = test_df[1:]\n",
    "\n",
    "VALDATA = StringIO(val_data)\n",
    "val_df = pd.read_csv(VALDATA, sep=\" \", header=None)\n",
    "val_df.columns = [\"word\", \"pos_tag\", \"chunk_tag\", \"NER_tag\"]\n",
    "val_df = val_df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9RUEJLld9U5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>farm</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ministers</td>\n",
       "      <td>nns</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>'</td>\n",
       "      <td>pos</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>meeting</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>of</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>causing</td>\n",
       "      <td>vbg</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>unjustified</td>\n",
       "      <td>jj</td>\n",
       "      <td>b-adjp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>alarm</td>\n",
       "      <td>nn</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>through</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>jj</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>generalisation</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>only</td>\n",
       "      <td>rb</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>france</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>b-loc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>britain</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>b-loc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>backed</td>\n",
       "      <td>vbd</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>fischler</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>'s</td>\n",
       "      <td>pos</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>proposal</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>the</td>\n",
       "      <td>dt</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>eu</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>'s</td>\n",
       "      <td>pos</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>scientific</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>veterinary</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>multidisciplinary</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>committees</td>\n",
       "      <td>nns</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>are</td>\n",
       "      <td>vbp</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>due</td>\n",
       "      <td>jj</td>\n",
       "      <td>b-adjp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>re-examine</td>\n",
       "      <td>vb</td>\n",
       "      <td>i-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>the</td>\n",
       "      <td>dt</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>issue</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>early</td>\n",
       "      <td>rb</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>next</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>month</td>\n",
       "      <td>nn</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>make</td>\n",
       "      <td>vb</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>nns</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>the</td>\n",
       "      <td>dt</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>senior</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>veterinary</td>\n",
       "      <td>jj</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>officials</td>\n",
       "      <td>nns</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word pos_tag chunk_tag NER_tag\n",
       "251               farm      nn      i-np       o\n",
       "252          ministers     nns      i-np       o\n",
       "253                  '     pos      b-np       o\n",
       "254            meeting      nn      i-np       o\n",
       "255                 of      in      b-pp       o\n",
       "256            causing     vbg      b-vp       o\n",
       "257        unjustified      jj    b-adjp       o\n",
       "258              alarm      nn      b-np       o\n",
       "259            through      in      b-pp       o\n",
       "260                          o         o     NaN\n",
       "261          dangerous      jj      b-np       o\n",
       "262     generalisation      nn      i-np       o\n",
       "263                  .       .         o       o\n",
       "264                          o         o     NaN\n",
       "265                  .       .         o       o\n",
       "266               only      rb      b-np       o\n",
       "267             france     nnp      i-np   b-loc\n",
       "268                and      cc      i-np       o\n",
       "269            britain     nnp      i-np   b-loc\n",
       "270             backed     vbd      b-vp       o\n",
       "271           fischler     nnp      b-np   b-per\n",
       "272                 's     pos      b-np       o\n",
       "273           proposal      nn      i-np       o\n",
       "274                  .       .         o       o\n",
       "275                the      dt      b-np       o\n",
       "276                 eu     nnp      i-np   b-org\n",
       "277                 's     pos      b-np       o\n",
       "278         scientific      jj      i-np       o\n",
       "279         veterinary      jj      i-np       o\n",
       "280                and      cc      i-np       o\n",
       "281  multidisciplinary      jj      i-np       o\n",
       "282         committees     nns      i-np       o\n",
       "283                are     vbp      b-vp       o\n",
       "284                due      jj    b-adjp       o\n",
       "285                 to      to      b-vp       o\n",
       "286         re-examine      vb      i-vp       o\n",
       "287                the      dt      b-np       o\n",
       "288              issue      nn      i-np       o\n",
       "289              early      rb      b-np       o\n",
       "290               next      jj      i-np       o\n",
       "291              month      nn      i-np       o\n",
       "292                and      cc         o       o\n",
       "293               make      vb      b-vp       o\n",
       "294    recommendations     nns      b-np       o\n",
       "295                 to      to      b-pp       o\n",
       "296                the      dt      b-np       o\n",
       "297             senior      jj      i-np       o\n",
       "298         veterinary      jj      i-np       o\n",
       "299          officials     nns      i-np       o\n",
       "300                  .       .         o       o"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[250:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI34wYUQiJr7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soccer</td>\n",
       "      <td>nn</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>japan</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-loc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get</td>\n",
       "      <td>vb</td>\n",
       "      <td>b-vp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lucky</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word pos_tag chunk_tag NER_tag\n",
       "1  soccer      nn      b-np       o\n",
       "2       -       :         o       o\n",
       "3   japan     nnp      b-np   b-loc\n",
       "4     get      vb      b-vp       o\n",
       "5   lucky     nnp      b-np       o"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Kpe0Nk5O-VA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cricket</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leicestershire</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word pos_tag chunk_tag NER_tag\n",
       "1         cricket     nnp      b-np       o\n",
       "2               -       :         o       o\n",
       "3  leicestershire     nnp      b-np   b-org\n",
       "4            take     nnp      i-np       o\n",
       "5            over      in      b-pp       o"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUrLZyDuc_Ms"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138    o\n",
       "1160    o\n",
       "1164    o\n",
       "1192    o\n",
       "1239    o\n",
       "Name: pos_tag, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This means that our model needs to predict NULL as named entity recognition\n",
    "\n",
    "val_df[val_df.isnull().any(axis=1)][\"pos_tag\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S59BcROOAiIR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75     o\n",
       "93     o\n",
       "260    o\n",
       "264    o\n",
       "366    o\n",
       "Name: pos_tag, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.isnull().any(axis=1)][\"pos_tag\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tj0KHCiXBGgF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7iJJstD3ggSR"
   },
   "outputs": [],
   "source": [
    "train_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
    "test_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
    "val_df[\"NER_tag\"].fillna(\"no_tag\", inplace=True)\n",
    "# train_df[train_df['NER_tag'] == 'no_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4boZP1SgwoF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cricket</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leicestershire</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>in</td>\n",
       "      <td>b-pp</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51573</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51574</th>\n",
       "      <td>--</td>\n",
       "      <td>:</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51575</th>\n",
       "      <td>dhaka</td>\n",
       "      <td>nnp</td>\n",
       "      <td>b-np</td>\n",
       "      <td>b-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51576</th>\n",
       "      <td>newsroom</td>\n",
       "      <td>nnp</td>\n",
       "      <td>i-np</td>\n",
       "      <td>i-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51577</th>\n",
       "      <td>880-2-506363</td>\n",
       "      <td>cd</td>\n",
       "      <td>i-np</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51577 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word pos_tag chunk_tag NER_tag\n",
       "1             cricket     nnp      b-np       o\n",
       "2                   -       :         o       o\n",
       "3      leicestershire     nnp      b-np   b-org\n",
       "4                take     nnp      i-np       o\n",
       "5                over      in      b-pp       o\n",
       "...               ...     ...       ...     ...\n",
       "51573               .       .         o       o\n",
       "51574              --       :         o       o\n",
       "51575           dhaka     nnp      b-np   b-org\n",
       "51576        newsroom     nnp      i-np   i-org\n",
       "51577    880-2-506363      cd      i-np       o\n",
       "\n",
       "[51577 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dropna()\n",
    "test_df.dropna()\n",
    "val_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHEifUShLJNn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204566"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qpl50_V-Uzmp"
   },
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dm-eSZQuPBpX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 26872\n",
      "Unique Ner Tags: ['no_tag', 'i-per', 'b-per', 'i-org', 'i-misc', 'i-loc', 'b-loc', 'b-org', 'o', 'b-misc'], number: 10\n"
     ]
    }
   ],
   "source": [
    "num_train = train_df.shape[0]\n",
    "num_val = val_df.shape[0]\n",
    "num_test = test_df.shape[0]\n",
    "\n",
    "train_word_set = set(train_df[\"word\"].to_list())\n",
    "test_word_set = set(test_df[\"word\"].to_list())\n",
    "val_word_set = set(val_df[\"word\"].to_list())\n",
    "\n",
    "word_set = train_word_set.union(test_word_set, val_word_set)\n",
    "word_list = list(word_set)\n",
    "word_list.extend(['start_tk', 'end_tk'])\n",
    "print(f\"Total unique words: {len(word_list)}\")\n",
    "\n",
    "ner_tags_list = list(set(train_df['NER_tag'].to_list()))\n",
    "print(f\"Unique Ner Tags: {ner_tags_list}, number: {len(ner_tags_list)}\")\n",
    "\n",
    "num_words = len(word_list)\n",
    "num_tags = len(ner_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBrzuz-LQQL6"
   },
   "outputs": [],
   "source": [
    "# convering the string data to indices dictionary\n",
    "\n",
    "word2idx = {w: i for i, w in enumerate(word_list)}\n",
    "tag2idx = {t: i for i, t in enumerate(ner_tags_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5T6lnnyVBOt"
   },
   "outputs": [],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEjJ0Q9kgCSI"
   },
   "outputs": [],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7tLFretLcYA"
   },
   "source": [
    "# Forming train and test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zK2ZiNlig9G"
   },
   "outputs": [],
   "source": [
    "def get_tagged_sentences(df):\n",
    "  tagged_list = [(w, t) for w, t in zip(df[\"word\"], df[\"NER_tag\"])]\n",
    "  final = []\n",
    "\n",
    "  for ele in tagged_list:\n",
    "\n",
    "    if not final:  # if list is empty\n",
    "      final.append([ele])\n",
    "    \n",
    "    elif final[-1][-1][0] == '.': # if the last tuple of last list is ('.', ..), form new list\n",
    "      final.append([ele])\n",
    "\n",
    "    else:       # add it to running list\n",
    "      final[-1].append(ele) \n",
    "\n",
    "  return final\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTrmpcAbQhoM"
   },
   "outputs": [],
   "source": [
    "train_sentences = get_tagged_sentences(train_df)\n",
    "test_sentences = get_tagged_sentences(test_df)\n",
    "val_sentences = get_tagged_sentences(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "El3FPswDQjm6"
   },
   "outputs": [],
   "source": [
    "val_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AA2mvqjLSYAp"
   },
   "outputs": [],
   "source": [
    "max_len_train = len(max(train_sentences, key=len))\n",
    "max_len_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvKmmmY1merl"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FggdzoYQijPx"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "\n",
    "# converting into indices\n",
    "X_train = [[word2idx[w[0]] for w in s] for s in train_sentences]\n",
    "X_val = [[word2idx[w[0]] for w in s] for s in val_sentences]\n",
    "X_test = [[word2idx[w[0]] for w in s] for s in test_sentences]\n",
    "\n",
    "# padding with Max len = 512\n",
    "X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value=MAX_LEN + 1)\n",
    "X_val = pad_sequences(maxlen=MAX_LEN, sequences=X_val, padding=\"post\", value=MAX_LEN + 1)\n",
    "X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value=MAX_LEN + 1)\n",
    "\n",
    "# converting tags to indices\n",
    "y_train = [[tag2idx[w[1]] for w in s] for s in train_sentences]\n",
    "y_val = [[tag2idx[w[1]] for w in s] for s in val_sentences]\n",
    "y_test = [[tag2idx[w[1]] for w in s] for s in test_sentences]\n",
    "\n",
    "# padding with Max len = 512\n",
    "y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
    "y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
    "y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"no_tag\"])\n",
    "\n",
    "\n",
    "# Making labels to one hot encoded\n",
    "\n",
    "y_train = [to_categorical(i, num_classes=num_tags) for i in y_train]\n",
    "y_val = [to_categorical(i, num_classes=num_tags) for i in y_val]\n",
    "y_test = [to_categorical(i, num_classes=num_tags) for i in y_test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BZoxsoVlB5e"
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCxUSUY8mimK"
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgXQ9s5iifhH"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59XokNFVEpW"
   },
   "outputs": [],
   "source": [
    "# Google's pretrained word2vec model\n",
    "\n",
    "word2vec_model = models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary=True, limit=10 ** 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFjza2m7nCn4"
   },
   "outputs": [],
   "source": [
    "a = word2vec_model[\"computer\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ultLjMESHg6_"
   },
   "outputs": [],
   "source": [
    "# np.random.rand(*a.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHs__xXUBLSz"
   },
   "outputs": [],
   "source": [
    "def get_word2vec_indices(vocabulary):\n",
    "  \"\"\"returns wordvec index list and the number of oov words\"\"\"\n",
    "\n",
    "  vocab_matrix  = np.zeros(shape=(len(word_list), word_vector_dim))\n",
    "  oov = 0\n",
    "\n",
    "  for s, idx in vocabulary.items():\n",
    "\n",
    "    try:\n",
    "      vocab_matrix[idx] = word2vec_model[s]\n",
    "\n",
    "    except:\n",
    "      if s == 'start_tk':\n",
    "        n = np.zeros_like(a)\n",
    "        n[0] = 1\n",
    "        vocab_matrix[idx] = n\n",
    "      elif s == 'end_tk':\n",
    "        n = np.zeros_like(a)\n",
    "        n[1] = 1\n",
    "        vocab_matrix[idx] = n\n",
    "      else:\n",
    "        oov += 1\n",
    "        vocab_matrix[idx] = np.random.randn(*a.shape)\n",
    "  return vocab_matrix, oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEDtsYIQEwJ9"
   },
   "outputs": [],
   "source": [
    "vocabulary_matrix, oov = get_word2vec_indices(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncDN8YKfFJd_"
   },
   "outputs": [],
   "source": [
    "vocabulary_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpsOS1FSC8je"
   },
   "outputs": [],
   "source": [
    "n = np.zeros_like(a)\n",
    "n[0] = 1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDEQlg9JZedt"
   },
   "outputs": [],
   "source": [
    "# window size = 2 * c + 1; \n",
    "def append_start_end_marker(sentences, C=1):\n",
    "  start_set = [('start_tk', 'no_tag') for i in range(C)]\n",
    "  end_set = [('end_tk', 'no_tag') for i in range(C)]\n",
    "\n",
    "  mod_sentences = []\n",
    "  n_gram = []\n",
    "  labels = []\n",
    "  for sent in sentences:\n",
    "    mod_sentences = [ *start_set,  *sent,  *end_set]\n",
    "\n",
    "    for i in range(len(mod_sentences) - (2 * C)):\n",
    "      n_gram.append([word[0] for word in mod_sentences[i: i+ 2 * C + 1]])\n",
    "      labels.append(mod_sentences[i + C ][1])\n",
    "      \n",
    "\n",
    "  return n_gram, labels\n",
    "\n",
    "train_n_grams, train_labels = append_start_end_marker(train_sentences, C)\n",
    "test_n_grams, test_labels = append_start_end_marker(test_sentences, C)\n",
    "val_n_grams, val_labels = append_start_end_marker(val_sentences, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxWXloUlblnx"
   },
   "outputs": [],
   "source": [
    "train_n_grams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74jclUGK9Vg7"
   },
   "outputs": [],
   "source": [
    "train_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRyHH1yv9fGT"
   },
   "outputs": [],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etHDEtyqI7lp"
   },
   "outputs": [],
   "source": [
    "vocabulary_matrix[word2idx['start_tk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tF38_HJ8Ir_I"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_wordvec_features(n_grams):\n",
    "\n",
    "  features = np.zeros(shape=(len(n_grams), (2 * C + 1) * word_vector_dim))\n",
    "\n",
    "  for i in range(len(n_grams)):\n",
    "    vec = np.array([vocabulary_matrix[word2idx[w]] for w in n_grams[i]]).flatten()\n",
    "    features[i] = vec\n",
    "  \n",
    "  return features\n",
    "\n",
    "################### run it only once, load it from pickle files ##################\n",
    "# train_features = get_wordvec_features(train_n_grams)\n",
    "# test_features = get_wordvec_features(test_n_grams)\n",
    "# val_features = get_wordvec_features(val_n_grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gx06aDWeewkT"
   },
   "outputs": [],
   "source": [
    "np.save('train_features.npy', train_features)\n",
    "np.save('test_features.npy', test_features)\n",
    "np.save('val_features.npy', val_features)\n",
    "\n",
    "np.save('vocab.npy', vocabulary_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gU9VAmXCkPaM"
   },
   "source": [
    "# Load saved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iczKJIrrhTh5"
   },
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "test_features = np.load('test_features.npy')\n",
    "val_features = np.load('val_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS-bc_Y3kWIC"
   },
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvFas3E0BIev"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 32\n",
    "\n",
    "\n",
    "# converting into indices\n",
    "X_train, oov_train = get_word2vec_indices(train_n_grams)\n",
    "X_val, oov_val = get_word2vec_indices(val_n_grams)\n",
    "X_test, oov_test = get_word2vec_indices(test_n_grams)\n",
    "\n",
    "# # padding with Max len = 512\n",
    "# X_train = pad_sequences(maxlen=MAX_LEN, sequences=X_train, padding=\"post\", value=MAX_LEN + 1)\n",
    "# X_val = pad_sequences(maxlen=MAX_LEN, sequences=X_val, padding=\"post\", value=MAX_LEN + 1)\n",
    "# X_test = pad_sequences(maxlen=MAX_LEN, sequences=X_test, padding=\"post\", value=MAX_LEN + 1)\n",
    "\n",
    "# converting tags to indices\n",
    "y_train = [tag2idx[w] for w in train_labels] \n",
    "y_val = [tag2idx[w] for w in val_labels]\n",
    "y_test = [tag2idx[w] for w in test_labels]\n",
    "\n",
    "\n",
    "# # padding with Max len = 512\n",
    "# y_train = pad_sequences(maxlen=MAX_LEN, sequences=y_train, padding=\"post\", value=tag2idx[\"o\"])\n",
    "# y_val = pad_sequences(maxlen=MAX_LEN, sequences=y_val, padding=\"post\", value=tag2idx[\"o\"])\n",
    "# y_test = pad_sequences(maxlen=MAX_LEN, sequences=y_test, padding=\"post\", value=tag2idx[\"o\"])\n",
    "\n",
    "\n",
    "# Making labels to one hot encoded\n",
    "\n",
    "y_train = [to_categorical(i, num_classes=num_tags) for i in y_train]\n",
    "y_val = [to_categorical(i, num_classes=num_tags) for i in y_val]\n",
    "y_test = [to_categorical(i, num_classes=num_tags) for i in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gbL8YynLp1_"
   },
   "source": [
    "### Number of OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAYYUCLi8gZ8"
   },
   "outputs": [],
   "source": [
    "print(f\"% of OOV words in train set = {oov_train/num_train}\")\n",
    "print(f\"% of OOV words in val set = {oov_val/num_val}\")\n",
    "print(f\"% of OOV words in test set = {oov_test/num_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4GMhul-LZ1E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgskAbjwy/JUmL99fisMrM",
   "collapsed_sections": [],
   "name": "Conll.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
